{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:28:54.601864Z",
     "start_time": "2018-05-15T09:28:54.554930Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "np.random.random(20121020)\n",
    "\n",
    "pl.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:16:56.372497Z",
     "start_time": "2018-05-15T09:16:55.473400Z"
    }
   },
   "outputs": [],
   "source": [
    "from ccal.access_gct import read_gct\n",
    "\n",
    "df = read_gct(\"test_data/input.gct\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:16:56.451432Z",
     "start_time": "2018-05-15T09:16:56.376558Z"
    }
   },
   "outputs": [],
   "source": [
    "from ccal.access_gct import write_gct\n",
    "\n",
    "write_gct(df, \"_output.gct\")\n",
    "\n",
    "os.remove(\"_output.gct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccal.access_gmt import read_gmt\n",
    "\n",
    "df = read_gmt(\"test_data/c1.all.v6.1.symbols.gmt\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:16:57.338204Z",
     "start_time": "2018-05-15T09:16:56.457290Z"
    }
   },
   "outputs": [],
   "source": [
    "from ccal.access_gmt import read_gmts\n",
    "\n",
    "df = read_gmts(\n",
    "    (\"test_data/c1.all.v6.1.symbols.gmt\", \"test_data/h.all.v6.1.symbols.gmt\")\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:16:57.515691Z",
     "start_time": "2018-05-15T09:16:57.345103Z"
    }
   },
   "outputs": [],
   "source": [
    "from ccal.access_gmt import write_gmt\n",
    "\n",
    "write_gmt(df, \"_output.gmt\")\n",
    "\n",
    "os.remove(\"_output.gmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:09:45.517550Z",
     "start_time": "2018-05-15T09:09:44.906100Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:09:45.517550Z",
     "start_time": "2018-05-15T09:09:44.906100Z"
    }
   },
   "outputs": [],
   "source": [
    "training_sample_x_feature = np.asarray(((0, 1),) * 8 + ((2, 3),) * 8)\n",
    "\n",
    "training_sample_x_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:09:45.838295Z",
     "start_time": "2018-05-15T09:09:45.709729Z"
    }
   },
   "outputs": [],
   "source": [
    "training_sample_class = np.asarray((0,) * 8 + (1,) * 8)\n",
    "\n",
    "training_sample_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:09:45.990946Z",
     "start_time": "2018-05-15T09:09:45.856023Z"
    }
   },
   "outputs": [],
   "source": [
    "testing_sample_x_feature = training_sample_x_feature[::-1]\n",
    "\n",
    "testing_sample_x_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:09:48.469916Z",
     "start_time": "2018-05-15T09:09:45.998042Z"
    }
   },
   "outputs": [],
   "source": [
    "from classification.train_and_classify import train_and_classify\n",
    "\n",
    "testing_sample_class = train_and_classify(\n",
    "    training_sample_x_feature, training_sample_class, testing_sample_x_feature\n",
    ")\n",
    "\n",
    "testing_sample_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:28:55.668422Z",
     "start_time": "2018-05-15T09:28:55.428950Z"
    }
   },
   "outputs": [],
   "source": [
    "n_row = 32\n",
    "\n",
    "n_column = 64\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    np.random.random_sample(size=(n_row, n_column)),\n",
    "    index=pd.Index((\"Index {}\".format(i) for i in range(n_row)), name=\"DF Row\"),\n",
    "    columns=pd.Index(\n",
    "        (\"Column {}\".format(i) for i in range(n_column)), name=\"DF Column\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = (2, 4, 8)\n",
    "\n",
    "k = \"K{}\".format(ks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_job = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:28:57.731699Z",
     "start_time": "2018-05-15T09:28:55.737405Z"
    }
   },
   "outputs": [],
   "source": [
    "from clustering.hierarchical_consensus_cluster import hierarchical_consensus_cluster\n",
    "\n",
    "establish_path(hierarchical_consensus_cluster.__name__, \"directory\")\n",
    "\n",
    "column_cluster, column_cluster__ccc = hierarchical_consensus_cluster(\n",
    "    df, ks[0], directory_path=hierarchical_consensus_cluster.__name__\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_cluster__ccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:28:59.510877Z",
     "start_time": "2018-05-15T09:28:58.281886Z"
    }
   },
   "outputs": [],
   "source": [
    "from clustering.hierarchical_consensus_cluster_with_ks import (\n",
    "    hierarchical_consensus_cluster_with_ks,\n",
    ")\n",
    "\n",
    "establish_path(hierarchical_consensus_cluster_with_ks.__name__, \"directory\")\n",
    "\n",
    "k_return = hierarchical_consensus_cluster_with_ks(\n",
    "    df, ks, n_job=n_job, directory_path=hierarchical_consensus_cluster_with_ks.__name__\n",
    ")\n",
    "\n",
    "k_return[k].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_return[k][\"column_cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_return[k][\"column_cluster.ccc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:29:06.750210Z",
     "start_time": "2018-05-15T09:29:00.185608Z"
    }
   },
   "outputs": [],
   "source": [
    "from clustering.nmf_consensus_cluster import nmf_consensus_cluster\n",
    "\n",
    "establish_path(nmf_consensus_cluster.__name__, \"directory\")\n",
    "\n",
    "w, h, e, w_element_cluster, w_element_cluster__ccc, h_element_cluster, h_element_cluster__ccc = nmf_consensus_cluster(\n",
    "    df, ks[0], directory_path=nmf_consensus_cluster.__name__\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:29:06.942006Z",
     "start_time": "2018-05-15T09:29:06.753031Z"
    }
   },
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:29:07.086179Z",
     "start_time": "2018-05-15T09:29:06.947335Z"
    }
   },
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:29:07.214197Z",
     "start_time": "2018-05-15T09:29:07.091699Z"
    }
   },
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:29:07.314397Z",
     "start_time": "2018-05-15T09:29:07.220362Z"
    }
   },
   "outputs": [],
   "source": [
    "w_element_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:29:07.400898Z",
     "start_time": "2018-05-15T09:29:07.319282Z"
    }
   },
   "outputs": [],
   "source": [
    "w_element_cluster__ccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_element_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_element_cluster__ccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:29:23.043947Z",
     "start_time": "2018-05-15T09:29:07.406319Z"
    }
   },
   "outputs": [],
   "source": [
    "from clustering.nmf_consensus_cluster_with_ks import nmf_consensus_cluster_with_ks\n",
    "\n",
    "establish_path(nmf_consensus_cluster_with_ks.__name__, \"directory\")\n",
    "\n",
    "k_return = nmf_consensus_cluster_with_ks(\n",
    "    df, ks, n_job=n_job, directory_path=nmf_consensus_cluster_with_ks.__name__\n",
    ")\n",
    "\n",
    "k_return[k].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_return[k][\"w\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_return[k][\"h\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_return[k][\"e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_return[k][\"w_element_cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_return[k][\"w_element_cluster.ccc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_return[k][\"h_element_cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_return[k][\"h_element_cluster.ccc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(hierarchical_consensus_cluster.__name__)\n",
    "\n",
    "shutil.rmtree(hierarchical_consensus_cluster_with_ks.__name__)\n",
    "\n",
    "shutil.rmtree(nmf_consensus_cluster.__name__)\n",
    "\n",
    "shutil.rmtree(nmf_consensus_cluster_with_ks.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:16:34.956452Z",
     "start_time": "2018-05-15T10:16:34.236354Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_x_sample = pd.read_table(\"feature_x_sample.tsv\", index_col=0).iloc[:16]\n",
    "\n",
    "feature_x_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:16:41.604640Z",
     "start_time": "2018-05-15T10:16:35.154166Z"
    }
   },
   "outputs": [],
   "source": [
    "from context.fit_skew_t_pdf import fit_skew_t_pdf\n",
    "\n",
    "global_n, global_location, global_scale, global_degree_of_freedom, global_shape = fit_skew_t_pdf(\n",
    "    feature_x_sample.unstack().values\n",
    ")\n",
    "\n",
    "template = (\n",
    "    \"N={}\\tLocation={:.3f}\\tScale={:.3f}\\tDegree of Freeedom={:.3f}\\tShape={:.3f}\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    template.format(\n",
    "        global_n, global_location, global_scale, global_degree_of_freedom, global_shape\n",
    "    )\n",
    ")\n",
    "\n",
    "_1d_array = feature_x_sample.iloc[0]\n",
    "\n",
    "n, location, scale, degree_of_freedom, shape = fit_skew_t_pdf(_1d_array.values)\n",
    "\n",
    "print(template.format(n, location, scale, degree_of_freedom, shape))\n",
    "\n",
    "n, location, scale, degree_of_freedom, shape = fit_skew_t_pdf(\n",
    "    _1d_array.values, fit_fixed_location=10, fit_fixed_scale=10\n",
    ")\n",
    "\n",
    "print(template.format(n, location, scale, degree_of_freedom, shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:16:43.463632Z",
     "start_time": "2018-05-15T10:16:41.615078Z"
    }
   },
   "outputs": [],
   "source": [
    "from context.compute_context import compute_context\n",
    "\n",
    "_1d_array = feature_x_sample.iloc[0].values\n",
    "\n",
    "context_dict = compute_context(_1d_array)\n",
    "\n",
    "context_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:16:43.552076Z",
     "start_time": "2018-05-15T10:16:43.471089Z"
    }
   },
   "outputs": [],
   "source": [
    "context_dict[\"fit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:16:43.661966Z",
     "start_time": "2018-05-15T10:16:43.559680Z"
    }
   },
   "outputs": [],
   "source": [
    "context_dict[\"grid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:16:43.856578Z",
     "start_time": "2018-05-15T10:16:43.681186Z"
    }
   },
   "outputs": [],
   "source": [
    "context_dict[\"pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:16:44.046296Z",
     "start_time": "2018-05-15T10:16:43.864102Z"
    }
   },
   "outputs": [],
   "source": [
    "context_dict[\"shape_pdf_reference\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:16:44.340597Z",
     "start_time": "2018-05-15T10:16:44.050346Z"
    }
   },
   "outputs": [],
   "source": [
    "context_dict[\"shape_context_indices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:16:44.488485Z",
     "start_time": "2018-05-15T10:16:44.369676Z"
    }
   },
   "outputs": [],
   "source": [
    "context_dict[\"location_pdf_reference\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:16:44.597583Z",
     "start_time": "2018-05-15T10:16:44.502390Z"
    }
   },
   "outputs": [],
   "source": [
    "context_dict[\"location_context_indices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:16:44.839707Z",
     "start_time": "2018-05-15T10:16:44.605066Z"
    }
   },
   "outputs": [],
   "source": [
    "context_dict[\"context_indices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:16:44.928851Z",
     "start_time": "2018-05-15T10:16:44.849128Z"
    }
   },
   "outputs": [],
   "source": [
    "context_dict[\"context_indices_like_array\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:18:36.106877Z",
     "start_time": "2018-05-15T10:16:44.933402Z"
    }
   },
   "outputs": [],
   "source": [
    "from context.plot_context import plot_context\n",
    "\n",
    "for feature, _1d_array in feature_x_sample.iloc[:8].iterrows():\n",
    "\n",
    "    plot_context(_1d_array, title=feature)\n",
    "\n",
    "    plot_context(\n",
    "        _1d_array,\n",
    "        global_location=global_location,\n",
    "        global_scale=global_scale,\n",
    "        global_degree_of_freedom=global_degree_of_freedom,\n",
    "        global_shape=global_shape,\n",
    "        title=feature,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:18:51.058631Z",
     "start_time": "2018-05-15T10:18:36.114419Z"
    }
   },
   "outputs": [],
   "source": [
    "from context.fit_skew_t_pdfs import fit_skew_t_pdfs\n",
    "\n",
    "feature_skew_t_pdf_fit_parameter = fit_skew_t_pdfs(feature_x_sample)\n",
    "\n",
    "feature_skew_t_pdf_fit_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:19:03.432815Z",
     "start_time": "2018-05-15T10:18:51.064534Z"
    }
   },
   "outputs": [],
   "source": [
    "from context.make_context_matrix import make_context_matrix\n",
    "\n",
    "feature_context_matrix = make_context_matrix(\n",
    "    feature_x_sample, skew_t_pdf_fit_parameter=feature_skew_t_pdf_fit_parameter\n",
    ")\n",
    "\n",
    "feature_context_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:12:25.102516Z",
     "start_time": "2018-05-15T09:12:25.011585Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_x_feature = np.asarray(((0, 1),) * 8 + ((2, 3),) * 8)\n",
    "\n",
    "sample_x_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:12:25.159951Z",
     "start_time": "2018-05-15T09:12:25.114511Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_class = np.asarray((0,) * 8 + (1,) * 8)\n",
    "\n",
    "sample_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:12:25.949093Z",
     "start_time": "2018-05-15T09:12:25.165171Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from cross_validation.cross_validate import cross_validate\n",
    "\n",
    "scores = cross_validate(SVC(), sample_x_feature, sample_class, 8, euclidean)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:14:00.460437Z",
     "start_time": "2018-05-15T09:14:00.357790Z"
    }
   },
   "outputs": [],
   "source": [
    "point_x_dimension = np.asarray(\n",
    "    (\n",
    "        (-8, -8, -8),\n",
    "        (-1, -1, -1),\n",
    "        (0, 0, 0),\n",
    "        (1, 1, 1),\n",
    "        (8, 8, 8),\n",
    "        (10, 10, 10),\n",
    "        (16, 16, 16),\n",
    "        (88, 88, 88),\n",
    "    )\n",
    ")\n",
    "\n",
    "point_x_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:14:33.888902Z",
     "start_time": "2018-05-15T09:14:00.481494Z"
    }
   },
   "outputs": [],
   "source": [
    "from dimension_scaling.mds import mds\n",
    "\n",
    "for n_target_dimension in (1, 2, 3):\n",
    "\n",
    "    print(\"MDS n_target_dimension={}:\".format(n_target_dimension))\n",
    "\n",
    "    point_x_target_dimension = mds(\n",
    "        n_target_dimension, point_x_dimension=point_x_dimension\n",
    "    )\n",
    "\n",
    "    print(point_x_target_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:14:42.523290Z",
     "start_time": "2018-05-15T09:14:33.910795Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import chebyshev\n",
    "\n",
    "point_x_target_dimension = mds(\n",
    "    2, point_x_dimension=point_x_dimension, distance_function=chebyshev\n",
    ")\n",
    "\n",
    "point_x_target_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:14:51.890212Z",
     "start_time": "2018-05-15T09:14:42.528891Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean, pdist, squareform\n",
    "\n",
    "point_x_target_dimension = mds(\n",
    "    2, distance__point_x_point=squareform(pdist(point_x_dimension))\n",
    ")\n",
    "\n",
    "point_x_target_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:30:00.294472Z",
     "start_time": "2018-05-15T09:29:59.560813Z"
    }
   },
   "outputs": [],
   "source": [
    "from tables import NoSuchNodeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:30:00.358750Z",
     "start_time": "2018-05-15T09:30:00.298727Z"
    }
   },
   "outputs": [],
   "source": [
    "grch_directory_path = os.path.abspath(os.path.expanduser(\".\"))\n",
    "\n",
    "gff3_gz_file_path = \"{}/Homo_sapiens.GRCh38.93.chr.gff3.gz\".format(grch_directory_path)\n",
    "\n",
    "assert os.path.isfile(gff3_gz_file_path), gff3_gz_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:32:20.020923Z",
     "start_time": "2018-05-15T09:30:00.362454Z"
    }
   },
   "outputs": [],
   "source": [
    "from feature.FeatureHDF5 import FeatureHDF5\n",
    "\n",
    "feature_hdf5 = FeatureHDF5(gff3_gz_file_path, reset=True)\n",
    "\n",
    "feature_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:32:20.594656Z",
     "start_time": "2018-05-15T09:32:20.027391Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_dict = feature_hdf5.get_features_by_name(\"KRAS\")\n",
    "\n",
    "feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:32:20.770574Z",
     "start_time": "2018-05-15T09:32:20.604862Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    feature_hdf5.get_features_by_name(\"Kwat\")\n",
    "\n",
    "except KeyError as exception:\n",
    "\n",
    "    warn(\"(get_features_by_name) KeyError: {}.\".format(exception))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:32:21.508520Z",
     "start_time": "2018-05-15T09:32:20.822924Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_dict = feature_hdf5.get_features_by_region(\"8\", 0, 800000)\n",
    "\n",
    "feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:32:21.728357Z",
     "start_time": "2018-05-15T09:32:21.532491Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    feature_hdf5.get_features_by_region(\"88888888\", 0, 800000)\n",
    "\n",
    "except NoSuchNodeError as exception:\n",
    "\n",
    "    warn(\"(get_features_by_region) NoSuchNodeError: {}.\".format(exception))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gene.select_gene_symbol import select_gene_symbol\n",
    "\n",
    "select_gene_symbol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:57:58.227713Z",
     "start_time": "2018-05-07T08:57:58.203692Z"
    }
   },
   "outputs": [],
   "source": [
    "grch_directory_path = os.path.expanduser(\"~/grch\")\n",
    "\n",
    "people_directory_path = os.path.expanduser(\"~/people\")\n",
    "\n",
    "reference_fasta_gz_file_path = \"{}/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz\".format(\n",
    "    grch_directory_path\n",
    ")\n",
    "\n",
    "assert os.path.isfile(reference_fasta_gz_file_path)\n",
    "\n",
    "reference_gff3_gz_file_path = os.path.abspath(\n",
    "    \"{}/Homo_sapiens.GRCh38.93.chr.gff3.gz\".format(grch_directory_path)\n",
    ")\n",
    "\n",
    "assert os.path.isfile(reference_gff3_gz_file_path)\n",
    "\n",
    "vcf_gz_file_path = os.path.abspath(\"{}/0/genome.vcf.gz\".format(people_directory_path))\n",
    "\n",
    "assert os.path.isfile(vcf_gz_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:58:01.703093Z",
     "start_time": "2018-05-07T08:57:58.259561Z"
    }
   },
   "outputs": [],
   "source": [
    "from genome.Genome import is_valid_vcf_gz\n",
    "\n",
    "is_valid_vcf_gz(vcf_gz_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:59:55.668047Z",
     "start_time": "2018-05-07T08:58:01.706669Z"
    }
   },
   "outputs": [],
   "source": [
    "from genome.Genome import Genome\n",
    "\n",
    "genome = Genome(\n",
    "    reference_fasta_gz_file_path,\n",
    "    reference_gff3_gz_file_path,\n",
    "    vcf_gz_file_path,\n",
    "    reset=True,\n",
    ")\n",
    "\n",
    "genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:59:56.028955Z",
     "start_time": "2018-05-07T08:59:55.678928Z"
    }
   },
   "outputs": [],
   "source": [
    "genome_dict = genome.explore_genome_by_variant(\"rs235\")\n",
    "\n",
    "genome_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:59:56.117166Z",
     "start_time": "2018-05-07T08:59:56.034203Z"
    }
   },
   "outputs": [],
   "source": [
    "genome_dict = genome.explore_genome_by_variant(\"rs88888888\")\n",
    "\n",
    "genome_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:59:56.575120Z",
     "start_time": "2018-05-07T08:59:56.123444Z"
    }
   },
   "outputs": [],
   "source": [
    "genome_dict = genome.explore_genome_by_gene(\"KRAS\")\n",
    "\n",
    "genome_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:59:56.684187Z",
     "start_time": "2018-05-07T08:59:56.582947Z"
    }
   },
   "outputs": [],
   "source": [
    "genome_dict = genome.explore_genome_by_gene(\"Kwat\")\n",
    "\n",
    "genome_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:59:57.302809Z",
     "start_time": "2018-05-07T08:59:56.692544Z"
    }
   },
   "outputs": [],
   "source": [
    "genome_dict = genome.explore_genome_by_region(\"8\", 0, 800000)\n",
    "\n",
    "genome_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:59:57.409356Z",
     "start_time": "2018-05-07T08:59:57.305398Z"
    }
   },
   "outputs": [],
   "source": [
    "genome_dict = genome.explore_genome_by_region(\"88888888\", 0, 800000)\n",
    "\n",
    "genome_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:23:13.816902Z",
     "start_time": "2018-05-15T09:23:11.763272Z"
    }
   },
   "outputs": [],
   "source": [
    "from geo.download_and_parse_geo_data import download_and_parse_geo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:23:13.816902Z",
     "start_time": "2018-05-15T09:23:11.763272Z"
    }
   },
   "outputs": [],
   "source": [
    "geo_dict = download_and_parse_geo_data(\"GSE26375\")\n",
    "\n",
    "geo_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:23:14.066745Z",
     "start_time": "2018-05-15T09:23:13.822510Z"
    }
   },
   "outputs": [],
   "source": [
    "geo_dict[\"id_x_sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:23:14.147528Z",
     "start_time": "2018-05-15T09:23:14.071686Z"
    }
   },
   "outputs": [],
   "source": [
    "geo_dict[\"id_gene_symbol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:23:14.384185Z",
     "start_time": "2018-05-15T09:23:14.151527Z"
    }
   },
   "outputs": [],
   "source": [
    "geo_dict[\"gene_x_sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:23:14.530314Z",
     "start_time": "2018-05-15T09:23:14.389894Z"
    }
   },
   "outputs": [],
   "source": [
    "geo_dict[\"information_x_sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:23:24.466916Z",
     "start_time": "2018-05-15T09:23:14.536906Z"
    }
   },
   "outputs": [],
   "source": [
    "geo_dict = download_and_parse_geo_data(\"GSE57820\")\n",
    "\n",
    "geo_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:23:24.609610Z",
     "start_time": "2018-05-15T09:23:24.471692Z"
    }
   },
   "outputs": [],
   "source": [
    "geo_dict[\"id_x_sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:23:24.655053Z",
     "start_time": "2018-05-15T09:23:24.615032Z"
    }
   },
   "outputs": [],
   "source": [
    "geo_dict[\"id_gene_symbol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:23:24.700546Z",
     "start_time": "2018-05-15T09:23:24.659758Z"
    }
   },
   "outputs": [],
   "source": [
    "geo_dict[\"gene_x_sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:23:24.832715Z",
     "start_time": "2018-05-15T09:23:24.707069Z"
    }
   },
   "outputs": [],
   "source": [
    "geo_dict[\"information_x_sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T01:24:15.365464Z",
     "start_time": "2018-05-02T01:24:15.108661Z"
    }
   },
   "outputs": [],
   "source": [
    "from sequencing_process.download_clinvar_vcf_gz import download_clinvar_vcf_gz\n",
    "from sequencing_process.make_reference_genome import make_reference_genome\n",
    "from sequencing_process.process_bam import (\n",
    "    check_bam_using_samtools_flagstat,\n",
    "    get_variants_from_bam_using_freebayes_and_multiprocess,\n",
    "    get_variants_from_bam_using_strelka,\n",
    "    mark_duplicates_in_bam_using_picard_markduplicates,\n",
    "    sort_and_index_bam_using_samtools_sort_and_index,\n",
    ")\n",
    "from sequencing_process.process_fasta import faidx_fasta\n",
    "from sequencing_process.process_fastq_gz import (\n",
    "    align_fastq_gzs_using_bwa_mem,\n",
    "    check_fastq_gzs_using_fastqc,\n",
    "    trim_fastq_gzs_using_skewer,\n",
    ")\n",
    "from sequencing_process.process_vcf_gz import (\n",
    "    annotate_vcf_gz_using_bcftools_annotate,\n",
    "    annotate_vcf_gz_using_snpeff,\n",
    "    filter_vcf_gz_using_bcftools_view,\n",
    "    rename_chromosome_of_vcf_gz_using_bcftools_annotate,\n",
    ")\n",
    "from sequencing_process.support.support.path import clean_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T01:24:15.395486Z",
     "start_time": "2018-05-02T01:24:15.368440Z"
    }
   },
   "outputs": [],
   "source": [
    "GRCH_DIRECTORY_PATH = clean_path(\"~/sequencing_process_grch\")\n",
    "\n",
    "assert os.path.isdir(GRCH_DIRECTORY_PATH)\n",
    "\n",
    "PEOPLE_DIRECTORY_PATH = clean_path(\"~/sequencing_process_people\")\n",
    "\n",
    "assert os.path.isdir(PEOPLE_DIRECTORY_PATH)\n",
    "\n",
    "REGIONS = tuple(\"chr{}\".format(i) for i in range(1, 23)) + (\"chrX\", \"chrY\", \"chrM\")\n",
    "\n",
    "N_JOB = 1\n",
    "\n",
    "MEMORY = \"8G\"\n",
    "\n",
    "VARIANT_METHOD = \"freebayes\"\n",
    "\n",
    "CLINVAR_VERSION = None\n",
    "\n",
    "OVERWRITE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T01:24:15.425202Z",
     "start_time": "2018-05-02T01:24:15.398135Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    FASTA_GZ_FILE_PATH = make_reference_genome(GRCH_DIRECTORY_PATH)\n",
    "\n",
    "except FileExistsError:\n",
    "\n",
    "    FASTA_GZ_FILE_PATH = \"{}/GCA_000001405.15_GRCh38_full_plus_hs38DH-extra_analysis_set.fa.gz\".format(\n",
    "        GRCH_DIRECTORY_PATH\n",
    "    )\n",
    "\n",
    "    assert os.path.isfile(FASTA_GZ_FILE_PATH)\n",
    "\n",
    "    FASTA_FILE_PATH = FASTA_GZ_FILE_PATH[:-3]\n",
    "\n",
    "    if not os.path.isfile(\"{}.fai\".format(FASTA_GZ_FILE_PATH)):\n",
    "\n",
    "        faidx_fasta(FASTA_FILE_PATH)\n",
    "\n",
    "try:\n",
    "\n",
    "    CLINVAR_VCF_GZ_FILE_PATH = download_clinvar_vcf_gz(\n",
    "        GRCH_DIRECTORY_PATH, version=CLINVAR_VERSION\n",
    "    )\n",
    "\n",
    "except FileExistsError:\n",
    "\n",
    "    CLINVAR_VCF_GZ_FILE_PATH = \"{}/{}\".format(\n",
    "        GRCH_DIRECTORY_PATH,\n",
    "        [\n",
    "            file_name\n",
    "            for file_name in os.listdir(GRCH_DIRECTORY_PATH)\n",
    "            if \"clinvar\" in file_name and file_name.endswith(\".vcf.gz\")\n",
    "        ][0],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T01:24:26.627411Z",
     "start_time": "2018-05-02T01:24:15.427956Z"
    }
   },
   "outputs": [],
   "source": [
    "fastq_gz_0_file_path = \"{}/simulation.bwa.read1.fastq.gz\".format(PEOPLE_DIRECTORY_PATH)\n",
    "\n",
    "assert os.path.isfile(fastq_gz_0_file_path)\n",
    "\n",
    "fastq_gz_1_file_path = \"{}/simulation.bwa.read2.fastq.gz\".format(PEOPLE_DIRECTORY_PATH)\n",
    "\n",
    "assert os.path.isfile(fastq_gz_1_file_path)\n",
    "\n",
    "fastq_gz_0_trimmed_file_path, fastq_gz_1_trimmed_file_path = trim_fastq_gzs_using_skewer(\n",
    "    (fastq_gz_0_file_path, fastq_gz_1_file_path),\n",
    "    output_directory_path=\"{}/trimmed_fastq_gz\".format(PEOPLE_DIRECTORY_PATH),\n",
    "    n_job=N_JOB,\n",
    "    overwrite=OVERWRITE,\n",
    ")\n",
    "\n",
    "check_fastq_gzs_using_fastqc(\n",
    "    (\n",
    "        fastq_gz_0_file_path,\n",
    "        fastq_gz_1_file_path,\n",
    "        fastq_gz_0_trimmed_file_path,\n",
    "        fastq_gz_1_trimmed_file_path,\n",
    "    ),\n",
    "    n_job=N_JOB,\n",
    "    overwrite=OVERWRITE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T01:24:36.898171Z",
     "start_time": "2018-05-02T01:24:26.631347Z"
    }
   },
   "outputs": [],
   "source": [
    "bam_file_path = align_fastq_gzs_using_bwa_mem(\n",
    "    (fastq_gz_0_trimmed_file_path, fastq_gz_1_trimmed_file_path),\n",
    "    FASTA_GZ_FILE_PATH,\n",
    "    n_job=N_JOB,\n",
    "    output_bam_file_path=\"{}/aligned.bam\".format(PEOPLE_DIRECTORY_PATH),\n",
    "    overwrite=OVERWRITE,\n",
    ")\n",
    "\n",
    "sorted_and_indexed_bam_file_path = sort_and_index_bam_using_samtools_sort_and_index(\n",
    "    bam_file_path, remove_input_bam_file_path=True, n_job=N_JOB, overwrite=OVERWRITE\n",
    ")\n",
    "\n",
    "duplicate_removed_bam_file_path = mark_duplicates_in_bam_using_picard_markduplicates(\n",
    "    sorted_and_indexed_bam_file_path,\n",
    "    memory=MEMORY,\n",
    "    remove_duplicates=True,\n",
    "    remove_input_bam_file_path_and_its_index=True,\n",
    "    n_job=N_JOB,\n",
    "    output_bam_file_path=\"{}/duplicate_removed.bam\".format(PEOPLE_DIRECTORY_PATH),\n",
    "    overwrite=OVERWRITE,\n",
    ")\n",
    "\n",
    "check_bam_using_samtools_flagstat(\n",
    "    duplicate_removed_bam_file_path, n_job=N_JOB, overwrite=OVERWRITE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T01:24:56.931056Z",
     "start_time": "2018-05-02T01:24:36.902214Z"
    }
   },
   "outputs": [],
   "source": [
    "if VARIANT_METHOD not in (\"freebayes\", \"strelka\"):\n",
    "\n",
    "    raise ValueError(\"Unknown VARIANT_METHOD: {}.\".format(VARIANT_METHOD))\n",
    "\n",
    "if VARIANT_METHOD == \"freebayes\":\n",
    "\n",
    "    vcf_gz_file_path = get_variants_from_bam_using_freebayes_and_multiprocess(\n",
    "        duplicate_removed_bam_file_path,\n",
    "        FASTA_FILE_PATH,\n",
    "        REGIONS,\n",
    "        n_job=N_JOB,\n",
    "        output_vcf_file_path=\"{}/{}.vcf\".format(PEOPLE_DIRECTORY_PATH, VARIANT_METHOD),\n",
    "        overwrite=OVERWRITE,\n",
    "    )\n",
    "\n",
    "    keep_filters = None\n",
    "\n",
    "    include_expression = \"10<=DP & 30<=QUAL & 10<=(QUAL/AO) & 1<=SRF & 1<=SRR & 1<=SAF & 1<=SAR & 1<=RPR & 1<=RPL\"\n",
    "\n",
    "elif VARIANT_METHOD == \"strelka\":\n",
    "\n",
    "    vcf_gz_file_path = get_variants_from_bam_using_strelka(\n",
    "        duplicate_removed_bam_file_path,\n",
    "        FASTA_FILE_PATH,\n",
    "        \"{}/strelka\".format(PEOPLE_DIRECTORY_PATH),\n",
    "        n_job=N_JOB,\n",
    "        overwrite=OVERWRITE,\n",
    "    )\n",
    "\n",
    "    keep_filters = (\"PASS\",)\n",
    "\n",
    "    include_expression = \"30<=QUAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T01:26:02.468212Z",
     "start_time": "2018-05-02T01:24:56.934994Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_vcf_gz_file_path = filter_vcf_gz_using_bcftools_view(\n",
    "    vcf_gz_file_path,\n",
    "    regions=REGIONS,\n",
    "    keep_filters=keep_filters,\n",
    "    include_expression=include_expression,\n",
    "    n_job=N_JOB,\n",
    "    output_vcf_file_path=\"{}/filtered.vcf\".format(PEOPLE_DIRECTORY_PATH),\n",
    "    overwrite=OVERWRITE,\n",
    ")\n",
    "\n",
    "chromosome_renamed_vcf_gz_file_path = rename_chromosome_of_vcf_gz_using_bcftools_annotate(\n",
    "    filtered_vcf_gz_file_path,\n",
    "    remove_input_vcf_gz_file_path_and_its_index=True,\n",
    "    n_job=N_JOB,\n",
    "    output_vcf_file_path=filtered_vcf_gz_file_path.replace(\n",
    "        \".vcf.gz\", \".chromosome_renamed.vcf\"\n",
    "    ),\n",
    "    overwrite=OVERWRITE,\n",
    ")\n",
    "\n",
    "snpeff_annotated_vcf_gz_file_path = annotate_vcf_gz_using_snpeff(\n",
    "    chromosome_renamed_vcf_gz_file_path,\n",
    "    \"GRCh38.86\",\n",
    "    memory=MEMORY,\n",
    "    remove_input_vcf_gz_file_path_and_its_index=True,\n",
    "    n_job=N_JOB,\n",
    "    output_vcf_file_path=chromosome_renamed_vcf_gz_file_path.replace(\n",
    "        \".vcf.gz\", \".snpeff.vcf\"\n",
    "    ),\n",
    "    overwrite=OVERWRITE,\n",
    ")\n",
    "\n",
    "clinvar_annotated_vcf_gz_file_path = annotate_vcf_gz_using_bcftools_annotate(\n",
    "    snpeff_annotated_vcf_gz_file_path,\n",
    "    CLINVAR_VCF_GZ_FILE_PATH,\n",
    "    (\"--columns =ID,INFO\",),\n",
    "    remove_input_vcf_gz_file_path_and_its_index=True,\n",
    "    n_job=N_JOB,\n",
    "    output_vcf_file_path=snpeff_annotated_vcf_gz_file_path.replace(\n",
    "        \".vcf.gz\", \".clinvar.vcf\"\n",
    "    ),\n",
    "    overwrite=OVERWRITE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:08:44.918287Z",
     "start_time": "2018-05-07T09:08:44.877580Z"
    }
   },
   "outputs": [],
   "source": [
    "w = pd.read_table(\"w.tsv\", index_col=0)\n",
    "\n",
    "w.columns.name = \"Factor\"\n",
    "\n",
    "h = pd.read_table(\"h.tsv\", index_col=0)\n",
    "\n",
    "h.columns.name = \"Sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:08:47.402509Z",
     "start_time": "2018-05-07T09:08:44.921622Z"
    }
   },
   "outputs": [],
   "source": [
    "from gps_map.GPSMap import GPSMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:09:18.942149Z",
     "start_time": "2018-05-07T09:08:47.406977Z"
    }
   },
   "outputs": [],
   "source": [
    "gps_map = GPSMap(w=w.T, h=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:09:19.246526Z",
     "start_time": "2018-05-07T09:09:18.951264Z"
    }
   },
   "outputs": [],
   "source": [
    "for w_or_h in (\"w\", \"h\"):\n",
    "\n",
    "    gps_map.plot_gps_map(w_or_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:09:22.949488Z",
     "start_time": "2018-05-07T09:09:19.263029Z"
    }
   },
   "outputs": [],
   "source": [
    "from gps_map.plot.plot.make_colorscale import make_colorscale\n",
    "\n",
    "for w_or_h, elements in ((\"w\", w.index), (\"h\", h.columns)):\n",
    "\n",
    "    annotation_types = (\"continuous\", \"categorical\", \"binary\")\n",
    "\n",
    "    annotation_x_element = pd.DataFrame(\n",
    "        [\n",
    "            np.random.random_sample(elements.size),\n",
    "            np.random.randint(0, high=3, size=elements.size),\n",
    "            np.random.randint(0, high=2, size=elements.size),\n",
    "        ],\n",
    "        index=annotation_types,\n",
    "        columns=elements,\n",
    "    )\n",
    "\n",
    "    annotation_x_element.iloc[0, 0] = np.nan\n",
    "\n",
    "    annotation_x_element.iloc[1, 1] = np.nan\n",
    "\n",
    "    annotation_x_element.iloc[2, 2] = np.nan\n",
    "\n",
    "    annotation_x_element.iloc[:, 3] = np.nan\n",
    "\n",
    "    gps_map.plot_gps_map(\n",
    "        w_or_h,\n",
    "        annotation_x_element=annotation_x_element,\n",
    "        annotation_types=annotation_types,\n",
    "    )\n",
    "\n",
    "    for annotation_type, annotation in annotation_x_element.iterrows():\n",
    "\n",
    "        gps_map.plot_gps_map(\n",
    "            w_or_h,\n",
    "            annotation_x_element=annotation.to_frame().T,\n",
    "            annotation_types=(annotation_type,),\n",
    "            annotation_colorscale=make_colorscale(\n",
    "                colors=(\"pink\", \"yellow\", \"purple\"), plot=False\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    annotation_x_element = pd.DataFrame(\n",
    "        [np.random.normal(size=elements.size)] * 3, columns=elements\n",
    "    )\n",
    "\n",
    "    gps_map.plot_gps_map(\n",
    "        w_or_h,\n",
    "        annotation_x_element=annotation_x_element,\n",
    "        annotation_std_maxs=(0.1, 1, 3),\n",
    "    )\n",
    "\n",
    "    gps_map.plot_gps_map(\n",
    "        w_or_h,\n",
    "        annotation_x_element=annotation_x_element.iloc[:1],\n",
    "        annotation_ranges=((0, 8),),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gps_map.plot.plot.make_random_color import make_random_color\n",
    "\n",
    "for w_or_h, element_labels in (\n",
    "    (\"w\", w.apply(np.argmax, axis=1).str[1:].astype(int)),\n",
    "    (\"h\", h.apply(np.argmax).str[1:].astype(int)),\n",
    "):\n",
    "\n",
    "    gps_map.set_element_labels(w_or_h, element_labels)\n",
    "\n",
    "    gps_map.plot_gps_map(w_or_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w_or_h, w_or_h_matrix in ((\"w\", w.T), (\"h\", h)):\n",
    "\n",
    "    predicted_element_labels = gps_map.predict(w_or_h, w_or_h_matrix.iloc[:, :8])\n",
    "\n",
    "    print(predicted_element_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:11:27.808293Z",
     "start_time": "2018-05-07T09:10:17.612658Z"
    }
   },
   "outputs": [],
   "source": [
    "for w_or_h in (\"w\", \"h\"):\n",
    "\n",
    "    gps_map.anneal_node_and_element_positions(\n",
    "        w_or_h, n_iteration=64, initial_temperature=0.01\n",
    "    )\n",
    "\n",
    "    gps_map.plot_gps_map(w_or_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:11:28.055466Z",
     "start_time": "2018-05-07T09:11:27.813895Z"
    }
   },
   "outputs": [],
   "source": [
    "h = pd.read_table(\"kras_gps_map/nmf_k9_h.tsv\", index_col=0)\n",
    "\n",
    "# https://github.com/UCSD-CCAL/onco_gps_paper_analysis/blob/master/code/8%20Define%20global%20cellular%20labels%20and%20make%20global%20Onco-GPS%20map.ipynb\n",
    "\n",
    "h = h.apply(lambda row: (row - row.mean()) / row.std(), axis=1)\n",
    "\n",
    "h = h.clip(lower=-3, upper=3)\n",
    "\n",
    "h = h.apply(lambda row: (row - row.min()) / (row.max() - row.min()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:11:34.232723Z",
     "start_time": "2018-05-07T09:11:28.060604Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/KwatME/gps_map/blob/e932c53e1d679a68c224cf62284fb9209235962f/onco_gps/GPSMap.py\n",
    "\n",
    "h = h.apply(lambda row: (row - row.mean()) / row.std(), axis=1)\n",
    "\n",
    "h = h.clip(lower=-3, upper=3)\n",
    "\n",
    "h = h.apply(lambda row: (row - row.min()) / (row.max() - row.min()), axis=1)\n",
    "\n",
    "# Euclidean distance is used instead in https://github.com/KwatME/gps_map/blob/e932c53e1d679a68c224cf62284fb9209235962f/onco_gps/GPSMap.py\n",
    "\n",
    "gps_map = GPSMap(h=h, h_pull_power=2.4, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:12:10.654231Z",
     "start_time": "2018-05-07T09:11:34.238395Z"
    }
   },
   "outputs": [],
   "source": [
    "h_element_labels = pd.read_table(\"kras_gps_map/hcc__k_x_h_column.tsv\", index_col=0).loc[\n",
    "    \"K15\"\n",
    "]\n",
    "\n",
    "gps_map.set_element_labels(\n",
    "    \"h\",\n",
    "    h_element_labels,\n",
    "    label_colors=(\n",
    "        \"#e74c3c\",\n",
    "        \"#ffd700\",\n",
    "        \"#4b0082\",\n",
    "        \"#993300\",\n",
    "        \"#4169e1\",\n",
    "        \"#90ee90\",\n",
    "        \"#f4bd60\",\n",
    "        \"#8b008b\",\n",
    "        \"#fa8072\",\n",
    "        \"#b0e0e6\",\n",
    "        \"#20d9ba\",\n",
    "        \"#da70d6\",\n",
    "        \"#d2691e\",\n",
    "        \"#dc143c\",\n",
    "        \"#2e8b57\",\n",
    "    ),\n",
    "    bandwidth_factor=5.6,\n",
    ")\n",
    "\n",
    "gps_map.plot_gps_map(\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_element_labels = gps_map.predict(\"h\", h)\n",
    "\n",
    "predicted_element_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gps_map.access_gps_map import dump_gps_map\n",
    "\n",
    "dump_gps_map(gps_map, \"gps_map.pickle.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gps_map.access_gps_map import load_gps_map\n",
    "\n",
    "gps_map = load_gps_map(\"gps_map.pickle.gz\")\n",
    "\n",
    "gps_map.plot_gps_map(\"h\")\n",
    "\n",
    "os.remove(\"gps_map.pickle.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:31:50.820917Z",
     "start_time": "2018-05-15T09:31:50.340764Z"
    }
   },
   "outputs": [],
   "source": [
    "n_gene = 80\n",
    "\n",
    "all_genes = pd.read_table(\"genes.txt\", squeeze=True)\n",
    "\n",
    "genes = np.random.choice(all_genes, size=n_gene, replace=False)\n",
    "\n",
    "genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:31:51.351662Z",
     "start_time": "2018-05-15T09:31:50.826812Z"
    }
   },
   "outputs": [],
   "source": [
    "n_sample = 8\n",
    "\n",
    "gene_x_sample = pd.DataFrame(\n",
    "    np.random.random_sample(size=(n_gene, n_sample)),\n",
    "    index=genes,\n",
    "    columns=(\"Sample {}\".format(i) for i in range(n_sample)),\n",
    ")\n",
    "\n",
    "gene_x_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:31:51.816539Z",
     "start_time": "2018-05-15T09:31:51.371983Z"
    }
   },
   "outputs": [],
   "source": [
    "n_gene_set = 8\n",
    "\n",
    "gene_sets = []\n",
    "\n",
    "for i in range(n_gene_set):\n",
    "\n",
    "    gene_sets.append(np.random.choice(genes, size=(i + 1) * 8, replace=False))\n",
    "\n",
    "gene_sets = pd.DataFrame(\n",
    "    gene_sets, index=tuple(\"Gene Set {}\".format(i) for i in range(n_gene_set))\n",
    ")\n",
    "\n",
    "gene_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:31:58.850062Z",
     "start_time": "2018-05-15T09:31:51.824769Z"
    }
   },
   "outputs": [],
   "source": [
    "from gsea.single_sample_gsea import single_sample_gsea\n",
    "\n",
    "score = single_sample_gsea(gene_x_sample.iloc[:, 0] - 0.5, gene_sets.iloc[0])\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsea.nd_array.nd_array.normalize_nd_array import normalize_nd_array\n",
    "\n",
    "for statistic in (\"ks\", \"auc\"):\n",
    "\n",
    "    gene_score = gene_x_sample.iloc[:, 0]\n",
    "\n",
    "    for normalization_method in (None, \"0-1\", \"-0-\"):\n",
    "\n",
    "        if normalization_method is not None:\n",
    "\n",
    "            gene_score = pd.Series(\n",
    "                normalize_nd_array(gene_score, None, normalization_method),\n",
    "                name=gene_score.name,\n",
    "                index=gene_score.index,\n",
    "            )\n",
    "\n",
    "        single_sample_gsea(\n",
    "            gene_score,\n",
    "            gene_sets.iloc[0],\n",
    "            statistic=statistic,\n",
    "            title=\"statistic={} & normalization_method={}\".format(\n",
    "                statistic, normalization_method\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:32:00.443357Z",
     "start_time": "2018-05-15T09:31:58.871340Z"
    }
   },
   "outputs": [],
   "source": [
    "from gsea.single_sample_gseas import single_sample_gseas\n",
    "\n",
    "score__gene_set_x_sample = single_sample_gseas(gene_x_sample, gene_sets, n_job=2)\n",
    "\n",
    "score__gene_set_x_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:32:03.995749Z",
     "start_time": "2018-05-15T09:32:00.449852Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "from gsea.gsea import gsea\n",
    "\n",
    "n_sample_per_phenotype = n_sample // 2\n",
    "\n",
    "phenotypes = np.array((0,) * n_sample_per_phenotype + (1,) * n_sample_per_phenotype)\n",
    "\n",
    "\n",
    "def function(x, y):\n",
    "\n",
    "    return pearsonr(x, y)[0]\n",
    "\n",
    "\n",
    "score_p_value = gsea(\n",
    "    gene_x_sample,\n",
    "    phenotypes,\n",
    "    gene_sets.iloc[0, :],\n",
    "    function,\n",
    "    statistic=\"ks\",\n",
    "    n_permutation=10,\n",
    "    permuting=\"gene\",\n",
    "    gene_score_name=\"Correlation\",\n",
    ")\n",
    "\n",
    "score_p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make gene x cellline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-27T22:22:28.369581Z",
     "start_time": "2017-08-27T22:22:19.255957Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load CCLE mutation-amplification-deletion x cellline\n",
    "mutation_amplification_deletion_x_cellline = gct.read_gct(\n",
    "    \"../data/ccle/mutation__gene_x_ccle_cellline.gct\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"mutation_amplification_deletion_x_cellline.shape: {}\".format(\n",
    "        mutation_amplification_deletion_x_cellline.shape\n",
    "    )\n",
    ")\n",
    "\n",
    "# Keep only mutations (*_MUT)\n",
    "mutation_x_cellline = mutation_amplification_deletion_x_cellline.loc[\n",
    "    mutation_amplification_deletion_x_cellline.index.str.endswith(\"MUT\")\n",
    "]\n",
    "\n",
    "print(\"mutation_x_cellline.shape: {}\".format(mutation_x_cellline.shape))\n",
    "\n",
    "# Remove '_MUT' suffix\n",
    "mutation_x_cellline.index = [l[0] for l in mutation_x_cellline.index.str.split(sep=\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-27T22:22:28.578983Z",
     "start_time": "2017-08-27T22:22:28.372782Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read Foundation One genes\n",
    "foundation_one_genes = (\n",
    "    gmt.read_gmts(\"../data/gene_sets/cancer_gene_sets/cancer_gene_sets.gmt\")\n",
    "    .loc[\"FoundationOne\"]\n",
    "    .dropna()\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "print(\"N Foundation One genes: {}\".format(len(foundation_one_genes)))\n",
    "\n",
    "# Keep only mutations in the Foundation One genes\n",
    "selected_mutation_x_cellline = mutation_x_cellline.loc[\n",
    "    [i in foundation_one_genes for i in mutation_x_cellline.index]\n",
    "]\n",
    "\n",
    "print(\"selected_mutation_x_cellline: {}\".format(selected_mutation_x_cellline.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make compound-sensitivity x cellline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-27T22:22:34.823688Z",
     "start_time": "2017-08-27T22:22:33.399926Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read CCLE compound-sensitivity x cellline\n",
    "compound_sensitivity_x_cellline = gct.read_gct(\n",
    "    \"../data/ccle/ctd2__compound_x_ccle_cellline.gct\"\n",
    ")\n",
    "\n",
    "# Flip value signs because lower the viability score, better the response\n",
    "compound_sensitivity_x_cellline *= -1\n",
    "\n",
    "compound_sensitivity_x_cellline = pd.DataFrame(\n",
    "    a2d.normalize(compound_sensitivity_x_cellline.values, \"0-1\"),\n",
    "    index=compound_sensitivity_x_cellline.index,\n",
    "    columns=compound_sensitivity_x_cellline.columns,\n",
    ")\n",
    "\n",
    "plot.plot_heatmap(\n",
    "    compound_sensitivity_x_cellline,\n",
    "    title=\"compound_sensitivity_x_cellline {}\".format(\n",
    "        compound_sensitivity_x_cellline.shape\n",
    "    ),\n",
    "    xlabel=\"Cellline\",\n",
    "    ylabel=\"Compound\",\n",
    ")\n",
    "\n",
    "# Get cell lines common in selected-mutation x cellline and compound-sensitivity x cellline\n",
    "common_celllines = (\n",
    "    selected_mutation_x_cellline.columns & compound_sensitivity_x_cellline.columns\n",
    ").sort_values()\n",
    "\n",
    "print(\"common_celllines.size: {}\".format(common_celllines.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match selected mutations to compound sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-27T22:22:44.186761Z",
     "start_time": "2017-08-27T22:22:41.739823Z"
    }
   },
   "outputs": [],
   "source": [
    "compound = \"PLX-4720\"\n",
    "print(\"Matching mutations to {} ...\".format(compound))\n",
    "\n",
    "compound_sensitivity = compound_sensitivity_x_cellline.loc[\n",
    "    compound, common_celllines\n",
    "].dropna()\n",
    "print(\"\\tcompound_sensitivity.size: {}\".format(compound_sensitivity.size))\n",
    "\n",
    "print()\n",
    "match_result = make_match_panel(\n",
    "    compound_sensitivity,\n",
    "    selected_mutation_x_cellline.loc[:, compound_sensitivity.index],\n",
    "    n_jobs=4,\n",
    "    n_features=10,\n",
    "    n_samplings=0,\n",
    "    n_permutations=0,\n",
    "    features_type=\"binary\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer compound response from mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-27T22:23:24.279575Z",
     "start_time": "2017-08-27T22:23:22.810439Z"
    }
   },
   "outputs": [],
   "source": [
    "mutation_1 = \"BRAF\"\n",
    "mutation_2 = \"KRAS\"\n",
    "\n",
    "print(\"Mutaiton 1: {}\".format(mutation_1))\n",
    "print(\"Mutaiton 2: {}\".format(mutation_2))\n",
    "\n",
    "m1 = np.array(selected_mutation_x_cellline.loc[mutation_1, compound_sensitivity.index])\n",
    "m2 = np.array(selected_mutation_x_cellline.loc[mutation_2, compound_sensitivity.index])\n",
    "r = np.array(compound_sensitivity)\n",
    "rb = (0.6 < r).astype(int)\n",
    "\n",
    "plot.plot_distribution(m1, title=\"{} Distribution\".format(mutation_1))\n",
    "plot.plot_distribution(m2, title=\"{} Distribution\".format(mutation_2))\n",
    "plot.plot_distribution(r, title=\"{} Distribution\".format(compound))\n",
    "plot.plot_distribution(rb, title=\"{} (binarized) Distribution\".format(compound))\n",
    "\n",
    "grid_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute P(R | Mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-27T22:25:47.287076Z",
     "start_time": "2017-08-27T22:25:43.287449Z"
    }
   },
   "outputs": [],
   "source": [
    "p_rb__m1, p_rb1__m1 = infer(\n",
    "    [m1, rb], grid_size=grid_size, target=1, variable_names=[mutation_1, compound]\n",
    ")\n",
    "\n",
    "p_rb__m2, p_rb1__m2 = infer(\n",
    "    [m2, rb], grid_size=grid_size, target=1, variable_names=[mutation_2, compound]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute P(R | M1, M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-27T22:25:57.824624Z",
     "start_time": "2017-08-27T22:25:50.672790Z"
    }
   },
   "outputs": [],
   "source": [
    "p_rb__m1m2, p_rb1__m1m2 = infer_assuming_independence(\n",
    "    [m1, m2, rb],\n",
    "    grid_size=grid_size,\n",
    "    target=1,\n",
    "    variable_names=[mutation_1, mutation_2, compound],\n",
    ")\n",
    "\n",
    "p_rb__m1m2, p_rb1__m1m2 = infer(\n",
    "    [m1, m2, rb],\n",
    "    grid_size=grid_size,\n",
    "    target=1,\n",
    "    variable_names=[mutation_1, mutation_2, compound],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Bayesian nomograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-27T22:25:58.723925Z",
     "start_time": "2017-08-27T22:25:58.687144Z"
    }
   },
   "outputs": [],
   "source": [
    "p_rb1 = rb.sum() / rb.size\n",
    "\n",
    "print(p_rb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-27T22:58:03.957015Z",
     "start_time": "2017-08-27T22:58:00.587544Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_bayesian_nomogram(\n",
    "    [mutation_1, mutation_2],\n",
    "    [m1, m2],\n",
    "    [p_rb__m1, p_rb__m2],\n",
    "    p_rb1,\n",
    "    1 - p_rb1,\n",
    "    n_lors_marks=2,\n",
    "    file_path=\"../results/nomogram.png\",\n",
    ")\n",
    "\n",
    "plot_bayesian_nomogram(\n",
    "    [mutation_1, mutation_2],\n",
    "    [m1, m2],\n",
    "    [p_rb__m1, p_rb__m2],\n",
    "    p_rb1,\n",
    "    1 - p_rb1,\n",
    "    sample=[1, 1],\n",
    "    n_lors_marks=2,\n",
    "    file_path=\"../results/nomogram_with_sample.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:32:27.685628Z",
     "start_time": "2018-05-15T09:32:26.669533Z"
    }
   },
   "outputs": [],
   "source": [
    "from information.compute_entropy import compute_entropy\n",
    "\n",
    "for arrar_1d in (\n",
    "    np.random.random_sample(8),\n",
    "    np.random.random_sample(16),\n",
    "    np.random.random_sample(32),\n",
    "    np.random.random_sample(64),\n",
    "    np.random.random_sample(128),\n",
    "    np.random.random_sample(256),\n",
    "    np.random.random_sample(512),\n",
    "    np.random.random_sample(1024),\n",
    "    np.random.random_sample(1000000),\n",
    "    np.asarray((0,) * 100),\n",
    "    np.asarray((1,) * 100),\n",
    "    np.asarray((1,) * 1000),\n",
    "    np.asarray((1,) * 10000),\n",
    "    np.asarray((1,) * 100000),\n",
    "    np.asarray((1,) * 1000000),\n",
    "):\n",
    "\n",
    "    entropy = compute_entropy(arrar_1d)\n",
    "\n",
    "    print(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:32:32.232401Z",
     "start_time": "2018-05-15T09:32:27.690390Z"
    }
   },
   "outputs": [],
   "source": [
    "from information.compute_information_coefficient import compute_information_coefficient\n",
    "from information.compute_information_distance import compute_information_distance\n",
    "\n",
    "for x, y in (\n",
    "    (np.asarray((0,) * 8),) * 2,\n",
    "    (np.asarray((1,) * 8),) * 2,\n",
    "    (np.asarray(range(8)), np.asarray(range(8))[::-1]),\n",
    "    (np.asarray((0, 1, 2, 3, 4, 5, 6, 7, 8, 7, 6, 5, 4, 3, 2, 1, 0)),) * 2,\n",
    "    (np.asarray((8, 7, 6, 5, 4, 3, 2, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8)),) * 2,\n",
    "    (np.asarray((0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0)),) * 2,\n",
    "    (\n",
    "        np.asarray((1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1)),\n",
    "        np.asarray((0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0)),\n",
    "    ),\n",
    "):\n",
    "\n",
    "    print(0)\n",
    "\n",
    "    print(x)\n",
    "\n",
    "    print(y)\n",
    "\n",
    "    information_coefficient = compute_information_coefficient(x, y)\n",
    "\n",
    "    information_distance = compute_information_distance(x, y)\n",
    "\n",
    "    print(\n",
    "        \"Information Coefficient = {:.3f}\\tInformation Distance = {:.3f}\".format(\n",
    "            information_coefficient, information_distance\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "\n",
    "x = np.asarray((0,) * n + (1,) * n + (2,) * n)\n",
    "\n",
    "print(x)\n",
    "\n",
    "for factor in (0.1, 0.5, 1, 2, 10, 100):\n",
    "\n",
    "    y = x * factor\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(y)\n",
    "\n",
    "    ic = compute_information_coefficient(x, y)\n",
    "\n",
    "    print(ic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:32:59.784783Z",
     "start_time": "2018-05-15T09:32:46.796195Z"
    }
   },
   "outputs": [],
   "source": [
    "from kernel_density.compute_bandwidths import compute_bandwidths\n",
    "\n",
    "coordiante_1d = np.asarray(range(16))\n",
    "\n",
    "for n_dimension in (1, 2, 8):\n",
    "\n",
    "    bandwidths = compute_bandwidths(\n",
    "        (coordiante_1d,) * n_dimension, (\"c\",) * n_dimension\n",
    "    )\n",
    "\n",
    "    print(bandwidths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:33:18.619153Z",
     "start_time": "2018-05-15T09:32:59.802493Z"
    }
   },
   "outputs": [],
   "source": [
    "from kernel_density.estimate_kernel_density import estimate_kernel_density\n",
    "\n",
    "for i, j in (\n",
    "    (np.asarray(range(8)), np.asarray(range(8))),\n",
    "    (np.asarray((0, 1, 2, 3)), np.asarray((1, 1, 0, 0))),\n",
    "    (np.asarray((0, 1, 2, 3)), np.asarray((0, 0, 1, 1))),\n",
    "    (np.asarray((1, 1, 0, 0)), np.asarray((0, 1, 2, 3))),\n",
    "    (np.asarray((0, 0, 1, 1)), np.asarray((0, 1, 2, 3))),\n",
    "):\n",
    "\n",
    "    ij = estimate_kernel_density((i, j))\n",
    "\n",
    "    pl.offline.iplot(\n",
    "        dict(\n",
    "            layout=dict(\n",
    "                width=400, height=400, xaxis=dict(title=\"j\"), yaxis=dict(title=\"i\")\n",
    "            ),\n",
    "            data=[dict(type=\"heatmap\", z=ij[::-1])],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:33:53.505903Z",
     "start_time": "2018-05-15T09:33:18.641074Z"
    }
   },
   "outputs": [],
   "source": [
    "coordiante_1d = np.asarray(range(8))\n",
    "\n",
    "n_dimension = 3\n",
    "\n",
    "ijk = estimate_kernel_density((coordiante_1d,) * n_dimension)\n",
    "\n",
    "ijk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:33:05.440601Z",
     "start_time": "2018-05-15T09:32:58.488553Z"
    }
   },
   "outputs": [],
   "source": [
    "from linear_model.correlate import correlate\n",
    "\n",
    "for x, y in (\n",
    "    (np.random.random_sample(16),) * 2,\n",
    "    (np.random.random_sample(16), np.random.random_sample(16)),\n",
    "    (np.asarray(range(16)), np.asarray(range(16, 0, -1))),\n",
    "):\n",
    "\n",
    "    r2, p_value = correlate(x, y, n_permutation=100, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:46:36.617163Z",
     "start_time": "2018-05-15T10:46:33.667703Z"
    }
   },
   "outputs": [],
   "source": [
    "from match.make_match_panel import make_match_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2d_array = np.asarray(((0, np.nan), (0, np.nan)))\n",
    "\n",
    "features = pd.DataFrame(\n",
    "    _2d_array,\n",
    "    index=(\"Index {}\".format(i) for i in range(_2d_array.shape[0])),\n",
    "    columns=(\"Column {}\".format(i) for i in range(_2d_array.shape[1])),\n",
    ")\n",
    "\n",
    "target = pd.Series(\n",
    "    np.random.normal(loc=0, scale=1, size=features.columns.size), index=features.columns\n",
    ")\n",
    "\n",
    "score_moe_p_value_fdr = make_match_panel(\n",
    "    target, features, n_sampling=1, n_permutation=1\n",
    ")\n",
    "\n",
    "score_moe_p_value_fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_index = 8\n",
    "\n",
    "n_column = 64\n",
    "\n",
    "features = pd.DataFrame(\n",
    "    np.random.random_sample(size=(n_index, n_column)),\n",
    "    index=(\"Index {}\".format(i) for i in range(n_index)),\n",
    "    columns=(\"Column {}\".format(i) for i in range(n_column)),\n",
    ")\n",
    "\n",
    "target = pd.Series(\n",
    "    np.random.normal(loc=0, scale=1, size=n_column),\n",
    "    name=\"TARGET\",\n",
    "    index=features.columns,\n",
    ")\n",
    "\n",
    "score_moe_p_value_fdr = make_match_panel(\n",
    "    target, features, n_sampling=2, n_permutation=1\n",
    ")\n",
    "\n",
    "score_moe_p_value_fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plot_only_sign in (\"-\", \"+\"):\n",
    "\n",
    "    score_moe_p_value_fdr = make_match_panel(\n",
    "        target, features, n_sampling=2, n_permutation=1, plot_only_sign=plot_only_sign\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:46:36.617163Z",
     "start_time": "2018-05-15T10:46:33.667703Z"
    }
   },
   "outputs": [],
   "source": [
    "for n_index, n_column in (\n",
    "    (8, 2),\n",
    "    (8, 4),\n",
    "    (8, 16),\n",
    "    (8, 32),\n",
    "    (8, 160),\n",
    "    (8, 320),\n",
    "    (8, 1600),\n",
    "    (8, 3200),\n",
    "    (1, 8),\n",
    "    (2, 8),\n",
    "    (4, 8),\n",
    "    (16, 8),\n",
    "    (32, 8),\n",
    "    (64, 8),\n",
    "    (128, 8),\n",
    "    (320, 8),\n",
    "    (640, 8),\n",
    "):\n",
    "\n",
    "    target = pd.Series(\n",
    "        np.random.random_sample(size=n_column),\n",
    "        index=(\"Column {}\".format(i) for i in range(n_column)),\n",
    "    )\n",
    "\n",
    "    features = pd.DataFrame(\n",
    "        np.random.random_sample(size=(n_index, n_column)),\n",
    "        index=(\"Index {}\".format(i) for i in range(n_index)),\n",
    "        columns=(\"Column {}\".format(i) for i in range(n_column)),\n",
    "    )\n",
    "\n",
    "    score_moe_p_value_fdr = pd.DataFrame(\n",
    "        np.random.random_sample(size=(features.shape[0], 4)),\n",
    "        index=(\"Index {}\".format(i) for i in range(n_index)),\n",
    "        columns=(\"Score\", \"0.95 MoE\", \"P-Value\", \"FDR\"),\n",
    "    )\n",
    "\n",
    "    score_moe_p_value_fdr = make_match_panel(\n",
    "        target,\n",
    "        features,\n",
    "        score_moe_p_value_fdr=score_moe_p_value_fdr,\n",
    "        extreme_feature_threshold=None,\n",
    "        title=\"{}-x-{} Match Panel\".format(n_index, n_column),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [0, 2]\n",
    "\n",
    "target = pd.Series(target, index=(\"Sample {}\".format(i) for i in range(len(target))))\n",
    "\n",
    "n_row = 8\n",
    "\n",
    "features = pd.DataFrame(\n",
    "    np.random.random_sample(size=(n_row, target.size)),\n",
    "    index=(\"Index {}\".format(i) for i in range(n_row)),\n",
    "    columns=target.index,\n",
    ")\n",
    "\n",
    "for random_seed in range(3):\n",
    "\n",
    "    score_moe_p_value_fdr = make_match_panel(\n",
    "        target,\n",
    "        features,\n",
    "        n_sampling=1,\n",
    "        n_permutation=1,\n",
    "        random_seed=random_seed,\n",
    "        target_type=\"binary\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [0, 2, 8, 0]\n",
    "\n",
    "target = pd.Series(target, index=(\"Sample {}\".format(i) for i in range(len(target))))\n",
    "\n",
    "n_row = 8\n",
    "\n",
    "features = pd.DataFrame(\n",
    "    np.random.random_sample(size=(n_row, target.size)),\n",
    "    index=(\"Index {}\".format(i) for i in range(n_row)),\n",
    "    columns=target.index,\n",
    ")\n",
    "\n",
    "score_moe_p_value_fdr = make_match_panel(\n",
    "    target,\n",
    "    features,\n",
    "    n_sampling=2,\n",
    "    n_permutation=1,\n",
    "    target_ascending=None,\n",
    "    target_type=\"categorical\",\n",
    ")\n",
    "\n",
    "score_moe_p_value_fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:47:59.764349Z",
     "start_time": "2018-05-15T10:46:36.621876Z"
    }
   },
   "outputs": [],
   "source": [
    "target = pd.read_table(\"target_0.tsv\", index_col=0, squeeze=True)\n",
    "\n",
    "features = pd.read_table(\"features_0.tsv\", index_col=0)\n",
    "\n",
    "score_moe_p_value_fdr = make_match_panel(\n",
    "    target, features, n_sampling=2, n_permutation=1, target_type=\"binary\"\n",
    ")\n",
    "\n",
    "score_moe_p_value_fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_moe_p_value_fdr = make_match_panel(\n",
    "    features.iloc[0], features.iloc[:1], n_sampling=2, n_permutation=1, plot_std=3\n",
    ")\n",
    "\n",
    "score_moe_p_value_fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_moe_p_value_fdr = make_match_panel(\n",
    "    features.iloc[0], features.iloc[:2], n_sampling=2, n_permutation=1, plot_std=3\n",
    ")\n",
    "\n",
    "score_moe_p_value_fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:48:04.273823Z",
     "start_time": "2018-05-15T10:47:59.781185Z"
    }
   },
   "outputs": [],
   "source": [
    "n_index = 24\n",
    "\n",
    "n_column = 16\n",
    "\n",
    "features = pd.DataFrame(\n",
    "    np.random.random_sample(size=(n_index, n_column)),\n",
    "    index=(\"Index {}\".format(i) for i in range(n_index)),\n",
    "    columns=(\"Column {}\".format(i) for i in range(n_column)),\n",
    ")\n",
    "\n",
    "features.iloc[:2, -2:] = np.nan\n",
    "\n",
    "for target in (\n",
    "    pd.Series((\"Aa\",) * 4 + (\"Bb\",) * 4 + (\"Cc\",) * 4 + (\"Aa\",) * 4),\n",
    "    pd.Series((0,) * 8 + (2,) * 8),\n",
    "    pd.Series((0,) * 1 + (1,) * 2 + (2,) * 13),\n",
    "    pd.Series((0,) * 2 + (1,) * 2 + (3,) * 12),\n",
    "):\n",
    "\n",
    "    target.index = (\"Column {}\".format(i) for i in range(n_column))\n",
    "\n",
    "    score_moe_p_value_fdr = make_match_panel(\n",
    "        target,\n",
    "        features,\n",
    "        target_ascending=None,\n",
    "        n_sampling=2,\n",
    "        n_permutation=1,\n",
    "        score_ascending=True,\n",
    "        target_type=\"categorical\",\n",
    "    )\n",
    "\n",
    "    print(score_moe_p_value_fdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:48:05.570577Z",
     "start_time": "2018-05-15T10:48:04.281086Z"
    }
   },
   "outputs": [],
   "source": [
    "n_index = 8\n",
    "\n",
    "n_column = 16\n",
    "\n",
    "target = pd.Series(\n",
    "    np.random.random_sample(size=n_column + 1),\n",
    "    index=(\"Column {}\".format(i) for i in range(n_column + 1)),\n",
    ")\n",
    "\n",
    "features = pd.DataFrame(\n",
    "    np.random.random_sample(size=(n_index, n_column)),\n",
    "    index=(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ {}\".format(i) for i in range(n_index)),\n",
    "    columns=(\"Column {}\".format(i) for i in range(n_column)),\n",
    ")\n",
    "\n",
    "features.iloc[0] = 0\n",
    "\n",
    "features.loc[\n",
    "    np.random.choice(features.index, size=features.index.size // 8 * 7, replace=False),\n",
    "    np.random.choice(\n",
    "        features.columns, size=features.columns.size // 8 * 7, replace=False\n",
    "    ),\n",
    "] = np.nan\n",
    "\n",
    "score_moe_p_value_fdr = make_match_panel(\n",
    "    target, features, n_sampling=2, n_permutation=1\n",
    ")\n",
    "\n",
    "score_moe_p_value_fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:48:08.065933Z",
     "start_time": "2018-05-15T10:48:05.590942Z"
    }
   },
   "outputs": [],
   "source": [
    "n_index = 8\n",
    "\n",
    "n_column = 64\n",
    "\n",
    "target = pd.Series(\n",
    "    np.random.random_sample(size=n_column),\n",
    "    index=(\"Column {}\".format(i) for i in range(n_column)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:48:08.065933Z",
     "start_time": "2018-05-15T10:48:05.590942Z"
    }
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame(\n",
    "    np.random.random_sample(size=(n_index, n_column)),\n",
    "    index=(\"Index {}\".format(i) for i in range(n_index)),\n",
    "    columns=(\"Column {}\".format(i) for i in range(n_column)),\n",
    ")\n",
    "\n",
    "score_moe_p_value_fdr = make_match_panel(target, features)\n",
    "\n",
    "score_moe_p_value_fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:48:08.065933Z",
     "start_time": "2018-05-15T10:48:05.590942Z"
    }
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame(\n",
    "    np.random.random_integers(0, 8, size=(n_index, n_column)),\n",
    "    index=(\"Index {}\".format(i) for i in range(n_index)),\n",
    "    columns=(\"Column {}\".format(i) for i in range(n_column)),\n",
    ")\n",
    "\n",
    "score_moe_p_value_fdr = make_match_panel(target, features, features_type=\"categorical\")\n",
    "\n",
    "score_moe_p_value_fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:48:08.065933Z",
     "start_time": "2018-05-15T10:48:05.590942Z"
    }
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame(\n",
    "    np.random.random_integers(0, 1, size=(n_index, n_column)),\n",
    "    index=(\"Index {}\".format(i) for i in range(n_index)),\n",
    "    columns=(\"Column {}\".format(i) for i in range(n_column)),\n",
    ")\n",
    "\n",
    "score_moe_p_value_fdr = make_match_panel(target, features, features_type=\"binary\")\n",
    "\n",
    "score_moe_p_value_fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:48:15.310369Z",
     "start_time": "2018-05-15T10:48:08.080994Z"
    }
   },
   "outputs": [],
   "source": [
    "from match.make_summary_match_panel import make_summary_match_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:48:15.310369Z",
     "start_time": "2018-05-15T10:48:08.080994Z"
    }
   },
   "outputs": [],
   "source": [
    "n_index = 4\n",
    "\n",
    "n_column = 8\n",
    "\n",
    "target = pd.Series(\n",
    "    np.random.random_sample(size=n_column),\n",
    "    name=\"TARGET\",\n",
    "    index=(\"Column {}\".format(i) for i in range(n_column)),\n",
    ")\n",
    "\n",
    "features_continuous = pd.DataFrame(\n",
    "    np.random.random_sample(size=(n_index, n_column)),\n",
    "    index=(\"Continuous {}\".format(i) for i in range(n_index)),\n",
    "    columns=target.index,\n",
    ")\n",
    "\n",
    "features_categorical = pd.DataFrame(\n",
    "    np.random.randint(0, 10, size=(n_index, n_column)),\n",
    "    index=(\"Categorical {}\".format(i) for i in range(n_index)),\n",
    "    columns=target.index,\n",
    ")\n",
    "\n",
    "features_binary = pd.DataFrame(\n",
    "    np.random.randint(0, 2, size=(n_index, n_column)),\n",
    "    index=(\"Binary {}\".format(i) for i in range(n_index)),\n",
    "    columns=target.index,\n",
    ")\n",
    "\n",
    "# features_continuous.iloc[:, 0] = np.nan\n",
    "\n",
    "# features_categorical.iloc[:, 1] = np.nan\n",
    "\n",
    "# features_binary.iloc[:, 2] = np.nan\n",
    "\n",
    "features_continuous.drop(target.index[-1], axis=1, inplace=True)\n",
    "\n",
    "features_categorical.drop(target.index[-2], axis=1, inplace=True)\n",
    "\n",
    "features_binary.drop(target.index[-5:-3], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:48:15.310369Z",
     "start_time": "2018-05-15T10:48:08.080994Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dicts = {\n",
    "    \"Continuous\": {\n",
    "        \"df\": features_continuous,\n",
    "        \"data_type\": \"continuous\",\n",
    "        \"emphasis\": \"low\",\n",
    "    },\n",
    "    \"Categorical\": {\n",
    "        \"df\": features_categorical,\n",
    "        \"data_type\": \"categorical\",\n",
    "        \"emphasis\": \"high\",\n",
    "    },\n",
    "    \"Binary\": {\"df\": features_binary, \"data_type\": \"binary\", \"emphasis\": \"low\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:48:15.310369Z",
     "start_time": "2018-05-15T10:48:08.080994Z"
    }
   },
   "outputs": [],
   "source": [
    "score_moe_p_value_fdr = make_match_panel(\n",
    "    target,\n",
    "    pd.concat((data_dict[\"df\"] for data_dict in data_dicts.values())),\n",
    "    n_sampling=1,\n",
    "    n_permutation=1,\n",
    "    plot_std=3,\n",
    ")\n",
    "\n",
    "score_moe_p_value_fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:48:15.310369Z",
     "start_time": "2018-05-15T10:48:08.080994Z"
    }
   },
   "outputs": [],
   "source": [
    "make_summary_match_panel(target, data_dicts, score_moe_p_value_fdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T10:48:15.310369Z",
     "start_time": "2018-05-15T10:48:08.080994Z"
    }
   },
   "outputs": [],
   "source": [
    "make_summary_match_panel(\n",
    "    target,\n",
    "    data_dicts,\n",
    "    score_moe_p_value_fdr,\n",
    "    plot_only_columns_shared_by_target_and_all_features=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_na = pd.DataFrame(\n",
    "    np.nan, index=features_continuous.index, columns=features_continuous.columns\n",
    ")\n",
    "\n",
    "make_summary_match_panel(\n",
    "    target,\n",
    "    {\"NA\": {\"df\": features_na, \"data_type\": \"continuous\", \"emphasis\": \"high\"}},\n",
    "    score_moe_p_value_fdr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from match.make_comparison_panel import make_comparison_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2d_array_0 = np.random.random_sample(size=(8, 2))\n",
    "\n",
    "_2d_array_1 = np.random.random_sample(size=(8, 4))\n",
    "\n",
    "comparison = make_comparison_panel(\n",
    "    _2d_array_0, _2d_array_1, name_0=\"2D Array 0\", name_1=\"2D Array 1\"\n",
    ")\n",
    "\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_column = 16\n",
    "\n",
    "df_0 = pd.DataFrame(\n",
    "    np.random.random_sample(size=(2, n_column)),\n",
    "    index=(\"DF 0 Index {}\".format(i) for i in range(2)),\n",
    "    columns=(\"DF 0 Column {}\".format(i) for i in range(n_column)),\n",
    ")\n",
    "\n",
    "df_1 = pd.DataFrame(\n",
    "    np.random.random_sample(size=(8, n_column)),\n",
    "    index=(\"DF 1 Index {}\".format(i) for i in range(8)),\n",
    "    columns=(\"DF 1 Column {}\".format(i) for i in range(n_column)),\n",
    ")\n",
    "\n",
    "comparison = make_comparison_panel(df_0, df_1, axis=1, name_0=\"DF 0\", name_1=\"DF 1\")\n",
    "\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matrix_factorization.nmf_by_multiple_V_and_H import nmf_by_multiple_V_and_H\n",
    "from matrix_factorization.nmf_by_multiplicative_update import (\n",
    "    nmf_by_multiplicative_update,\n",
    ")\n",
    "from matrix_factorization.nmf_by_sklearn import nmf_by_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_R_norms(R_norms, title=None):\n",
    "\n",
    "    if title is None:\n",
    "\n",
    "        title = \"NMF Convergence\"\n",
    "\n",
    "    pl.offline.iplot(\n",
    "        dict(\n",
    "            layout=dict(\n",
    "                width=640,\n",
    "                height=640,\n",
    "                title=title,\n",
    "                xaxis=dict(title=\"Iteration\"),\n",
    "                yaxis=dict(title=\"Residual Matrix Norm\"),\n",
    "            ),\n",
    "            data=[\n",
    "                dict(type=\"scatter\", name=i, x=list(range(R_norms_.size)), y=R_norms_)\n",
    "                for i, R_norms_ in enumerate(R_norms)\n",
    "            ],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_Ws_and_Hs(Ws, Hs):\n",
    "\n",
    "    for i, W in enumerate(Ws):\n",
    "\n",
    "        pl.offline.iplot(\n",
    "            dict(\n",
    "                layout=dict(\n",
    "                    width=320,\n",
    "                    height=640,\n",
    "                    title=\"W {}\".format(i),\n",
    "                    xaxis=dict(title=\"k\"),\n",
    "                    yaxis=dict(title=\"m\"),\n",
    "                ),\n",
    "                data=[\n",
    "                    dict(\n",
    "                        type=\"heatmap\", z=W[::-1], colorscale=\"Picnic\", showscale=False\n",
    "                    )\n",
    "                ],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    for i, H in enumerate(Hs):\n",
    "\n",
    "        pl.offline.iplot(\n",
    "            dict(\n",
    "                layout=dict(\n",
    "                    width=640,\n",
    "                    height=320,\n",
    "                    title=\"H {}\".format(i),\n",
    "                    xaxis=dict(title=\"n\"),\n",
    "                    yaxis=dict(title=\"k\"),\n",
    "                ),\n",
    "                data=[\n",
    "                    dict(\n",
    "                        type=\"heatmap\", z=H[::-1], colorscale=\"Picnic\", showscale=False\n",
    "                    )\n",
    "                ],\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 160\n",
    "\n",
    "n = 80\n",
    "\n",
    "V = np.random.random_sample(size=(m, n))\n",
    "\n",
    "V += abs(V.min())\n",
    "\n",
    "Vs = (V, V * 10)\n",
    "\n",
    "for V in Vs:\n",
    "\n",
    "    print(V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "\n",
    "n_iteration = int(1e3)\n",
    "\n",
    "random_seed = 20121020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_R_norms = []\n",
    "\n",
    "for V in Vs:\n",
    "\n",
    "    W, H, R_norms = nmf_by_multiplicative_update(\n",
    "        V, k, n_iteration=n_iteration, random_seed=random_seed\n",
    "    )\n",
    "\n",
    "    plot_Ws_and_Hs((W,), (H,))\n",
    "\n",
    "    print(\"R norm (multiplicative_update): {:.2f}\".format(R_norms[-1]))\n",
    "\n",
    "    individual_R_norms.append(R_norms)\n",
    "\n",
    "    W_by_sklean, H_by_sklean, R_by_sklean = nmf_by_sklearn(\n",
    "        V, k, n_iteration=n_iteration, random_seed=random_seed\n",
    "    )\n",
    "\n",
    "    plot_Ws_and_Hs((W_by_sklean,), (H_by_sklean,))\n",
    "\n",
    "    print(\"R norm (sklean): {:.2f}\".format(R_by_sklean))\n",
    "\n",
    "plot_R_norms(individual_R_norms, title=\"NMF Independently\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, Hs, R_norms = nmf_by_multiple_V_and_H(\n",
    "    Vs, k, n_iteration=n_iteration, random_seed=random_seed\n",
    ")\n",
    "\n",
    "plot_Ws_and_Hs((W,), Hs)\n",
    "\n",
    "print(\n",
    "    \"R norm (multiple_V_and_H): {}\".format(\n",
    "        \", \".join(\"{:.2f}\".format(float_) for float_ in R_norms[:, -1])\n",
    "    )\n",
    ")\n",
    "\n",
    "plot_R_norms(R_norms, title=\"NMF Together\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nd_array.apply_function_on_2_1d_arrays import apply_function_on_2_1d_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_1d_array_0 = np.asarray((np.nan, -1, 0, 2, 4, 8))\n",
    "\n",
    "_1d_array_1 = np.asarray((8, np.inf, -np.inf, 4, 2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(_1d_array_0, _1d_array_1):\n",
    "\n",
    "    return _1d_array_0 + _1d_array_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    function_return = apply_function_on_2_1d_arrays(_1d_array_0, _1d_array_1, function)\n",
    "\n",
    "    print(function_return)\n",
    "\n",
    "except ValueError as exception:\n",
    "\n",
    "    print(exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_return = apply_function_on_2_1d_arrays(\n",
    "    _1d_array_0, _1d_array_1, function, raise_for_bad=False\n",
    ")\n",
    "\n",
    "function_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    function_return = apply_function_on_2_1d_arrays(\n",
    "        _1d_array_0, _1d_array_1, function, raise_for_bad=False, use_only_good=False\n",
    "    )\n",
    "\n",
    "    print(function_return)\n",
    "\n",
    "except ValueError as exception:\n",
    "\n",
    "    print(exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    function_return = apply_function_on_2_1d_arrays(\n",
    "        _1d_array_0, _1d_array_1, function, n_required=4, raise_for_bad=False\n",
    "    )\n",
    "\n",
    "    print(function_return)\n",
    "\n",
    "except ValueError as exception:\n",
    "\n",
    "    print(exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_return = apply_function_on_2_1d_arrays(\n",
    "    _1d_array_0,\n",
    "    _1d_array_1,\n",
    "    function,\n",
    "    n_required=4,\n",
    "    raise_for_n_less_than_required=False,\n",
    "    raise_for_bad=False,\n",
    ")\n",
    "\n",
    "function_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_permutation = 100\n",
    "\n",
    "for p_value_direction in (\"less\", \"great\"):\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(p_value_direction)\n",
    "\n",
    "    function_return = apply_function_on_2_1d_arrays(\n",
    "        _1d_array_0,\n",
    "        _1d_array_1,\n",
    "        euclidean,\n",
    "        n_permutation=n_permutation,\n",
    "        p_value_direction=p_value_direction,\n",
    "        raise_for_bad=False,\n",
    "    )\n",
    "\n",
    "    print(function_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:25.181618Z",
     "start_time": "2018-05-15T09:34:25.095596Z"
    }
   },
   "outputs": [],
   "source": [
    "from nd_array.apply_function_on_2_2d_arrays_slices import (\n",
    "    apply_function_on_2_2d_arrays_slices,\n",
    ")\n",
    "\n",
    "_2d_array_0 = np.random.random_sample(size=(8, 2))\n",
    "\n",
    "_2d_array_1 = np.random.random_sample(size=(8, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:25.181618Z",
     "start_time": "2018-05-15T09:34:25.095596Z"
    }
   },
   "outputs": [],
   "source": [
    "function_return = apply_function_on_2_2d_arrays_slices(\n",
    "    _2d_array_0, _2d_array_1, euclidean, 0\n",
    ")\n",
    "\n",
    "function_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:25.181618Z",
     "start_time": "2018-05-15T09:34:25.095596Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    function_return = apply_function_on_2_2d_arrays_slices(\n",
    "        _2d_array_0, _2d_array_1, euclidean, 1\n",
    "    )\n",
    "\n",
    "    print(function_return)\n",
    "\n",
    "except ValueError as exception:\n",
    "\n",
    "    print(exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:25.230729Z",
     "start_time": "2018-05-15T09:34:25.184068Z"
    }
   },
   "outputs": [],
   "source": [
    "from nd_array.check_nd_array_for_bad import check_nd_array_for_bad\n",
    "\n",
    "for nd_array in (\n",
    "    np.asarray((np.nan, 0, 1)),\n",
    "    np.asarray((0, np.inf, 1)),\n",
    "    np.asarray((0, 1, -np.inf)),\n",
    "    np.asarray((np.nan, np.inf, -np.inf)),\n",
    "):\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(nd_array)\n",
    "\n",
    "    try:\n",
    "\n",
    "        is_bad = check_nd_array_for_bad(nd_array)\n",
    "\n",
    "        print(is_bad)\n",
    "\n",
    "    except ValueError as exception:\n",
    "\n",
    "        print(exception)\n",
    "\n",
    "    is_bad = check_nd_array_for_bad(nd_array, raise_for_bad=False)\n",
    "\n",
    "    print(is_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:25.268767Z",
     "start_time": "2018-05-15T09:34:25.234226Z"
    }
   },
   "outputs": [],
   "source": [
    "from nd_array.clip_nd_array_by_standard_deviation import (\n",
    "    clip_nd_array_by_standard_deviation,\n",
    ")\n",
    "\n",
    "nd_array = np.random.normal(size=16)\n",
    "\n",
    "nd_array.max(), nd_array.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:25.268767Z",
     "start_time": "2018-05-15T09:34:25.234226Z"
    }
   },
   "outputs": [],
   "source": [
    "nd_array_clipped_by_standard_deviation = clip_nd_array_by_standard_deviation(\n",
    "    nd_array, 1\n",
    ")\n",
    "\n",
    "nd_array_clipped_by_standard_deviation.max(), nd_array_clipped_by_standard_deviation.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:25.268767Z",
     "start_time": "2018-05-15T09:34:25.234226Z"
    }
   },
   "outputs": [],
   "source": [
    "nd_array[0] = np.nan\n",
    "\n",
    "nd_array[1] = np.inf\n",
    "\n",
    "nd_array[2] = -np.inf\n",
    "\n",
    "nd_array_clipped_by_standard_deviation = clip_nd_array_by_standard_deviation(\n",
    "    nd_array, 1, raise_for_bad=False\n",
    ")\n",
    "\n",
    "nd_array_clipped_by_standard_deviation.max(), nd_array_clipped_by_standard_deviation.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:25.391597Z",
     "start_time": "2018-05-15T09:34:25.337609Z"
    }
   },
   "outputs": [],
   "source": [
    "from nd_array.cluster_2d_array_slices import cluster_2d_array_slices\n",
    "\n",
    "_2d_array = np.asarray(\n",
    "    ((0, 0), (-2, 2), (-4, 4), (-8, 8), (0, 0), (-4, 4), (-8, 8), (-2, 2))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:25.391597Z",
     "start_time": "2018-05-15T09:34:25.337609Z"
    }
   },
   "outputs": [],
   "source": [
    "indices = cluster_2d_array_slices(_2d_array, 0)\n",
    "\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:25.391597Z",
     "start_time": "2018-05-15T09:34:25.337609Z"
    }
   },
   "outputs": [],
   "source": [
    "indices = cluster_2d_array_slices(\n",
    "    _2d_array, 0, groups=np.asarray((1,) * 4 + (0,) * 2 + (1,) * 2)\n",
    ")\n",
    "\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:25.391597Z",
     "start_time": "2018-05-15T09:34:25.337609Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    indices = cluster_2d_array_slices(\n",
    "        _2d_array, 0, groups=np.asarray((1,) * 4 + (0,) * 2 + (1,) * 1)\n",
    "    )\n",
    "\n",
    "    print(indices)\n",
    "\n",
    "except ValueError as exception:\n",
    "\n",
    "    print(exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:25.438551Z",
     "start_time": "2018-05-15T09:34:25.396390Z"
    }
   },
   "outputs": [],
   "source": [
    "from nd_array.compute_empirical_p_value import compute_empirical_p_value\n",
    "\n",
    "value = 0\n",
    "\n",
    "random_values = np.asarray((-1, 0, 2, 4, 8))\n",
    "\n",
    "for p_value_direction in (\"less\", \"great\"):\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(p_value_direction)\n",
    "\n",
    "    p_value = compute_empirical_p_value(value, random_values, p_value_direction)\n",
    "\n",
    "    print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:26.316487Z",
     "start_time": "2018-05-15T09:34:25.442705Z"
    }
   },
   "outputs": [],
   "source": [
    "from nd_array.compute_empirical_p_values_and_fdrs import (\n",
    "    compute_empirical_p_values_and_fdrs,\n",
    ")\n",
    "\n",
    "values = np.asarray((-1, 0, 2, 4, 8))\n",
    "\n",
    "random_values = np.asarray(range(10))\n",
    "\n",
    "for p_value_direction in (\"less_or_great\", \"less\", \"great\"):\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(p_value_direction)\n",
    "\n",
    "    p_values, fdrs = compute_empirical_p_values_and_fdrs(\n",
    "        values, random_values, p_value_direction\n",
    "    )\n",
    "\n",
    "    print(p_values, fdrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:26.442469Z",
     "start_time": "2018-05-15T09:34:26.386701Z"
    }
   },
   "outputs": [],
   "source": [
    "from nd_array.compute_nd_array_margin_of_error import compute_nd_array_margin_of_error\n",
    "\n",
    "for nd_array in (\n",
    "    np.random.normal(size=10),\n",
    "    np.asarray((8,)),\n",
    "    np.asarray((np.nan,)),\n",
    "    np.asarray((8, np.nan)),\n",
    "):\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(nd_array)\n",
    "\n",
    "    margin_of_error = compute_nd_array_margin_of_error(nd_array, raise_for_bad=False)\n",
    "\n",
    "    print(margin_of_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:26.542244Z",
     "start_time": "2018-05-15T09:34:26.501608Z"
    }
   },
   "outputs": [],
   "source": [
    "from nd_array.get_1d_array_unique_objects_in_order import (\n",
    "    get_1d_array_unique_objects_in_order,\n",
    ")\n",
    "\n",
    "_1d_array = np.asarray((-1, 0, 2, 4, 8, -1, 0, 2, 4, 8))\n",
    "\n",
    "unique_objects_in_order = get_1d_array_unique_objects_in_order(_1d_array)\n",
    "\n",
    "unique_objects_in_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nd_array.get_intersections_between_2_1d_arrays import (\n",
    "    get_intersections_between_2_1d_arrays,\n",
    ")\n",
    "\n",
    "_1d_array_0 = np.asarray((-1, 0, 2, 4, 8, 4, 2, 0, -1))\n",
    "\n",
    "_1d_array_1 = np.asarray((8, 4, 2, 0, -1, 0, 2, 4, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.offline.iplot(\n",
    "    [\n",
    "        dict(type=\"scatter\", x=tuple(range(_1d_array_0.size)), y=_1d_array_0),\n",
    "        dict(type=\"scatter\", x=tuple(range(_1d_array_1.size)), y=_1d_array_1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "is_intesection = get_intersections_between_2_1d_arrays(_1d_array_0, _1d_array_1)\n",
    "\n",
    "is_intesection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:27.455640Z",
     "start_time": "2018-05-15T09:34:26.596268Z"
    }
   },
   "outputs": [],
   "source": [
    "_1d_array_0 += 1\n",
    "\n",
    "pl.offline.iplot(\n",
    "    [\n",
    "        dict(type=\"scatter\", x=tuple(range(_1d_array_0.size)), y=_1d_array_0),\n",
    "        dict(type=\"scatter\", x=tuple(range(_1d_array_1.size)), y=_1d_array_1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "is_intesection = get_intersections_between_2_1d_arrays(_1d_array_0, _1d_array_1)\n",
    "\n",
    "is_intesection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:27.840330Z",
     "start_time": "2018-05-15T09:34:27.746946Z"
    }
   },
   "outputs": [],
   "source": [
    "from nd_array.log_nd_array import log_nd_array\n",
    "\n",
    "for nd_array in (\n",
    "    np.asarray((1, 2)),\n",
    "    np.asarray((0, 1, 2)),\n",
    "    np.asarray((-1, 0, 1, 2)),\n",
    "    np.asarray((1, 2, np.nan, np.inf, -np.inf)),\n",
    "    np.asarray((0, 1, 2, np.nan, np.inf, -np.inf)),\n",
    "    np.asarray((-1, 0, 1, 2, np.nan, np.inf, -np.inf)),\n",
    "    np.linspace(0, 2, 11),\n",
    "):\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(nd_array)\n",
    "\n",
    "    for shift_as_necessary_to_achieve_min_before_logging in (0, 1):\n",
    "\n",
    "        for log_base in (\n",
    "            #'2',\n",
    "            \"e\",\n",
    "            #'10',\n",
    "        ):\n",
    "\n",
    "            print()\n",
    "\n",
    "            print(shift_as_necessary_to_achieve_min_before_logging, log_base)\n",
    "\n",
    "            nd_array_logged = log_nd_array(\n",
    "                nd_array,\n",
    "                shift_as_necessary_to_achieve_min_before_logging=shift_as_necessary_to_achieve_min_before_logging,\n",
    "                log_base=log_base,\n",
    "                raise_for_bad=False,\n",
    "            )\n",
    "\n",
    "            print(nd_array_logged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nd_array.make_coordinates_for_reflection import make_coordinates_for_reflection\n",
    "\n",
    "coordinates = np.asarray(range(10))\n",
    "\n",
    "coordinates_for_reflection = make_coordinates_for_reflection(\n",
    "    coordinates, coordinates[1]\n",
    ")\n",
    "\n",
    "coordinates_for_reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:27.513952Z",
     "start_time": "2018-05-15T09:34:27.458615Z"
    }
   },
   "outputs": [],
   "source": [
    "from nd_array.make_mesh_grid_coordinates_per_axis import (\n",
    "    make_mesh_grid_coordinates_per_axis,\n",
    ")\n",
    "\n",
    "mesh_grid_coordinates_per_axis = make_mesh_grid_coordinates_per_axis(\n",
    "    (0, 0), (8, 8), (2, 2)\n",
    ")\n",
    "\n",
    "mesh_grid_coordinates_per_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:27.577833Z",
     "start_time": "2018-05-15T09:34:27.517718Z"
    }
   },
   "outputs": [],
   "source": [
    "from nd_array.nd_array_is_sorted import nd_array_is_sorted\n",
    "\n",
    "for nd_array in (\n",
    "    np.asarray((0, 1, -1)),\n",
    "    np.asarray((-1, 0, 1)),\n",
    "    np.asarray((1, 0, -1)),\n",
    "    np.asarray((0, 0, 0)),\n",
    "    np.asarray((0, 1)),\n",
    "    np.asarray((1, 0)),\n",
    "):\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(nd_array)\n",
    "\n",
    "    is_sorted = nd_array_is_sorted(nd_array)\n",
    "\n",
    "    print(is_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:27.742204Z",
     "start_time": "2018-05-15T09:34:27.584485Z"
    }
   },
   "outputs": [],
   "source": [
    "from nd_array.normalize_nd_array import normalize_nd_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:27.742204Z",
     "start_time": "2018-05-15T09:34:27.584485Z"
    }
   },
   "outputs": [],
   "source": [
    "for _1d_array in (\n",
    "    np.asarray((-1, 0, 1)),\n",
    "    np.asarray((-1, -np.inf, 0, np.nan, 1, np.inf)),\n",
    "    np.asarray((0, 0)),\n",
    "    np.asarray((1, 1)),\n",
    "    np.asarray((2,)),\n",
    "):\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(_1d_array)\n",
    "\n",
    "    for method in (\"-0-\", \"0-1\", \"sum\", \"rank\"):\n",
    "\n",
    "        print()\n",
    "\n",
    "        print(method)\n",
    "\n",
    "        try:\n",
    "\n",
    "            normalized_1d_array = normalize_nd_array(\n",
    "                _1d_array, None, method, raise_for_bad=False\n",
    "            )\n",
    "\n",
    "            print(normalized_1d_array)\n",
    "\n",
    "        except ValueError as exception:\n",
    "\n",
    "            print(exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:27.742204Z",
     "start_time": "2018-05-15T09:34:27.584485Z"
    }
   },
   "outputs": [],
   "source": [
    "for _2d_array in (\n",
    "    np.asarray(((0, 1, 2), (3, 4, 5), (6, 7, 8)), dtype=float),\n",
    "    np.asarray(((np.nan, 0, 1, 2), (3, np.inf, 4, 5), (6, 7, -np.inf, 8))),\n",
    "):\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(_2d_array)\n",
    "\n",
    "    for axis in (None, 0, 1):\n",
    "\n",
    "        for method in (\"-0-\", \"0-1\", \"sum\", \"rank\"):\n",
    "\n",
    "            print()\n",
    "\n",
    "            print(axis, method)\n",
    "\n",
    "            normalized_2d_array = normalize_nd_array(\n",
    "                _2d_array, axis, method, raise_for_bad=False\n",
    "            )\n",
    "\n",
    "            print(normalized_2d_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:34:27.908722Z",
     "start_time": "2018-05-15T09:34:27.843668Z"
    }
   },
   "outputs": [],
   "source": [
    "from nd_array.shuffle_each_2d_array_slice import shuffle_each_2d_array_slice\n",
    "\n",
    "_2d_array = np.asarray((np.asarray(range(10)), np.asarray(range(10))[::-1]))\n",
    "\n",
    "for axis in (0, 1):\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(axis)\n",
    "\n",
    "    _2d_array_shuffled = shuffle_each_2d_array_slice(_2d_array, axis)\n",
    "\n",
    "    print(_2d_array_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:20:36.644901Z",
     "start_time": "2018-05-07T09:20:35.962000Z"
    }
   },
   "outputs": [],
   "source": [
    "from plot.make_colorscale import make_colorscale\n",
    "from plot.style import (\n",
    "    BINARY_COLORS_RUBY_EMERALD,\n",
    "    BINARY_COLORS_WHITE_BLACK,\n",
    "    CATEGORICAL_COLORS,\n",
    "    CONTINUOUS_COLORSCALE_FOR_MATCH,\n",
    ")\n",
    "\n",
    "for colors in (\n",
    "    CATEGORICAL_COLORS,\n",
    "    BINARY_COLORS_WHITE_BLACK,\n",
    "    BINARY_COLORS_RUBY_EMERALD,\n",
    "):\n",
    "\n",
    "    colorscale = make_colorscale(colors=colors)\n",
    "\n",
    "colorscale = make_colorscale(colorscale=CONTINUOUS_COLORSCALE_FOR_MATCH)\n",
    "\n",
    "colorscale = make_colorscale(colormap=\"ocean\")\n",
    "\n",
    "colorscale = make_colorscale(n_category=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:20:36.788779Z",
     "start_time": "2018-05-07T09:20:36.700852Z"
    }
   },
   "outputs": [],
   "source": [
    "from plot.make_random_color import make_random_color\n",
    "\n",
    "make_random_color(\"hex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:20:36.920184Z",
     "start_time": "2018-05-07T09:20:36.803616Z"
    }
   },
   "outputs": [],
   "source": [
    "from plot.plot_bar import plot_bar\n",
    "\n",
    "positions = ((\"Position 0\",), (\"Position 1\",), (\"Position 2\",))\n",
    "\n",
    "heights = ((2,), (4,), (8,))\n",
    "\n",
    "colors = (\"Red\", \"Green\", \"Blue\")\n",
    "\n",
    "for orientation, xs, ys in ((\"v\", positions, heights), (\"h\", heights, positions)):\n",
    "\n",
    "    plot_bar(\n",
    "        xs,\n",
    "        ys,\n",
    "        names=colors,\n",
    "        colors=colors,\n",
    "        position_labels=colors,\n",
    "        position_label_colors=colors,\n",
    "        orientation=orientation,\n",
    "        xaxis_dtick=2,\n",
    "        yaxis_dtick=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:20:37.216100Z",
     "start_time": "2018-05-07T09:20:37.013576Z"
    }
   },
   "outputs": [],
   "source": [
    "from plot.plot_bubble_map import plot_bubble_map\n",
    "\n",
    "n_row = 8\n",
    "\n",
    "n_column = 16\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    np.random.random_sample(size=(n_row, n_column)),\n",
    "    index=tuple(\"Index {}\".format(i) for i in range(n_row)),\n",
    "    columns=tuple(\"Column {}\".format(j) for j in range(n_column)),\n",
    ")\n",
    "\n",
    "df.iloc[0, 1] = 1.6\n",
    "\n",
    "print(df)\n",
    "\n",
    "plot_bubble_map(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot.plot_color_text import plot_color_text\n",
    "\n",
    "plot_color_text((\"#ff0000\", \"#0000ff\"), (\"Red\", \"Blue\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:20:37.296650Z",
     "start_time": "2018-05-07T09:20:37.220445Z"
    }
   },
   "outputs": [],
   "source": [
    "from plot.plot_distributions import plot_distributions\n",
    "\n",
    "x = np.random.random_sample(size=80)\n",
    "\n",
    "plot_distributions((x, x * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:20:37.817873Z",
     "start_time": "2018-05-07T09:20:37.300120Z"
    }
   },
   "outputs": [],
   "source": [
    "from plot.plot_heat_map import plot_heat_map\n",
    "\n",
    "df = pd.DataFrame([(0, 3), (2, 1)], index=(\"0\", \"1\"))\n",
    "\n",
    "plot_heat_map(df)\n",
    "\n",
    "plot_heat_map(df.values)\n",
    "\n",
    "df.index = (\"_0\", \"_1\")\n",
    "\n",
    "plot_heat_map(df)\n",
    "\n",
    "plot_heat_map(df.values)\n",
    "\n",
    "df = pd.DataFrame(np.random.random_sample(size=(8, 16)))\n",
    "\n",
    "indices = [0, 1]\n",
    "\n",
    "df.iloc[indices, indices] = np.nan\n",
    "\n",
    "df.index = (\"Index {}\".format(i) for i in range(df.shape[0]))\n",
    "\n",
    "df.columns = (\"Column {}\".format(i) for i in range(df.shape[1]))\n",
    "\n",
    "column_annotation = np.random.randint(0, high=df.shape[1] // 2, size=df.shape[1])\n",
    "\n",
    "row_annotation = np.random.randint(0, high=df.shape[0] // 2, size=df.shape[0])\n",
    "\n",
    "plot_heat_map(\n",
    "    df,\n",
    "    column_annotation=column_annotation,\n",
    "    column_annotation_str={\n",
    "        a: \"Column Group {}\".format(a) for a in set(column_annotation)\n",
    "    },\n",
    "    column_annotation_kwargs={\"textangle\": -90, \"yshift\": 88},\n",
    "    row_annotation=row_annotation,\n",
    "    row_annotation_str={a: \"Row Group {}\".format(a) for a in set(row_annotation)},\n",
    "    row_annotation_kwargs={\"xshift\": 80},\n",
    "    colorbar_x=1.16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:20:38.344979Z",
     "start_time": "2018-05-07T09:20:38.249945Z"
    }
   },
   "outputs": [],
   "source": [
    "from plot.plot_pie import plot_pie\n",
    "\n",
    "n = 8\n",
    "\n",
    "values = np.random.randint(0, 10, size=n)\n",
    "\n",
    "labels = tuple(\"Label {}\".format(i) for i in range(n))\n",
    "\n",
    "annotation_color = {\"A\" * (i + 1): make_random_color(\"hex\") for i in range(n)}\n",
    "\n",
    "plot_pie(values, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:20:38.428023Z",
     "start_time": "2018-05-07T09:20:38.348292Z"
    }
   },
   "outputs": [],
   "source": [
    "from plot.plot_points import plot_points\n",
    "\n",
    "x = np.linspace(-8, 8, 80)\n",
    "\n",
    "y = np.linspace(-16, 16, 80)\n",
    "\n",
    "plot_points((x, x), (y, y * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:20:38.640144Z",
     "start_time": "2018-05-07T09:20:38.432162Z"
    }
   },
   "outputs": [],
   "source": [
    "from plot.plot_table import plot_table\n",
    "\n",
    "df = pd.DataFrame(np.random.randint(0, 1, size=(16, 8)))\n",
    "\n",
    "df.index = (\"Index {}\".format(i) for i in range(df.shape[0]))\n",
    "\n",
    "df.columns = (\"Column {}\".format(i) for i in range(df.shape[1]))\n",
    "\n",
    "plot_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot.plot_violin_or_box import plot_violin_or_box\n",
    "\n",
    "n = 80\n",
    "\n",
    "y = np.random.random_sample(size=n)\n",
    "\n",
    "ys = (y, y * 2)\n",
    "\n",
    "for violin_or_box in (\"violin\", \"box\"):\n",
    "\n",
    "    plot_violin_or_box(ys, violin_or_box=violin_or_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:36:27.541762Z",
     "start_time": "2018-05-15T09:36:25.113862Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:36:28.226979Z",
     "start_time": "2018-05-15T09:36:27.718823Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_table(\"titanic.tsv\", index_col=0)\n",
    "\n",
    "df = df[[\"sex\", \"age\", \"fare\", \"survived\"]].dropna()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:36:32.320959Z",
     "start_time": "2018-05-15T09:36:28.241752Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"../../nd_array\")\n",
    "\n",
    "from nd_array.log_nd_array import log_nd_array\n",
    "from probability.plot.plot.plot_distributions import plot_distributions\n",
    "\n",
    "g = np.asarray(df[\"sex\"] == \"male\", dtype=int)\n",
    "\n",
    "g_name = \"Gender\"\n",
    "\n",
    "a = np.asarray(df[\"age\"])\n",
    "\n",
    "a_name = \"Age\"\n",
    "\n",
    "f = log_nd_array(\n",
    "    df[\"fare\"].values, shift_as_necessary_to_achieve_min_before_logging=\"0<\"\n",
    ")\n",
    "\n",
    "f_name = \"Fare\"\n",
    "\n",
    "s = np.asarray(df[\"survived\"])\n",
    "\n",
    "s_name = \"Survival\"\n",
    "\n",
    "plot_distributions(\n",
    "    (g, a, f, s),\n",
    "    names=(g_name, a_name, f_name, s_name),\n",
    "    title=\"Variable Distributions\",\n",
    "    xaxis_title=\"Variable Value\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:36:32.555517Z",
     "start_time": "2018-05-15T09:36:32.355179Z"
    }
   },
   "outputs": [],
   "source": [
    "p_s1 = (s == 1).sum() / s.size\n",
    "\n",
    "p_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:36:32.794005Z",
     "start_time": "2018-05-15T09:36:32.570037Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:36:33.172053Z",
     "start_time": "2018-05-15T09:36:32.801506Z"
    }
   },
   "outputs": [],
   "source": [
    "from probability.infer import infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:36:36.773395Z",
     "start_time": "2018-05-15T09:36:33.177534Z"
    }
   },
   "outputs": [],
   "source": [
    "p_s__g, p_s1__g = infer((g, s), grid_size=grid_size, target=1, names=(g_name, s_name))\n",
    "\n",
    "p_s__a, p_s1__a = infer((a, s), grid_size=grid_size, target=1, names=(a_name, s_name))\n",
    "\n",
    "p_s__f, p_s1__f = infer((f, s), grid_size=grid_size, target=1, names=(f_name, s_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:37:04.471741Z",
     "start_time": "2018-05-15T09:36:36.797632Z"
    }
   },
   "outputs": [],
   "source": [
    "from probability.infer_assuming_independence import infer_assuming_independence\n",
    "\n",
    "p_s__a_f, p_s1__a_f = infer(\n",
    "    (a, f, s), grid_size=grid_size, target=1, names=(a_name, f_name, s_name)\n",
    ")\n",
    "\n",
    "p_s__a_f_naive, p_s1__a_f_naive = infer_assuming_independence(\n",
    "    (a, f, s), grid_size=grid_size, target=1, names=(a_name, f_name, s_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:37:20.370751Z",
     "start_time": "2018-05-15T09:37:04.477354Z"
    }
   },
   "outputs": [],
   "source": [
    "from nd_array.compute_empirical_p_value import compute_empirical_p_value\n",
    "from nd_array.normalize_nd_array import normalize_nd_array\n",
    "\n",
    "maths = (\n",
    "    \"P(S = 1 | G)\",\n",
    "    \"P(S = 1 | A)\",\n",
    "    \"P(S = 1 | F)\",\n",
    "    \"P(S = 1 | A, F)\",\n",
    "    \"P(S = 1 | A, F) (naive)\",\n",
    ")\n",
    "\n",
    "math_roc = {math: {} for math in maths}\n",
    "\n",
    "for math, p_s1__v, vs in zip(\n",
    "    maths,\n",
    "    (p_s1__g, p_s1__a, p_s1__f, p_s1__a_f, p_s1__a_f_naive),\n",
    "    ((g,), (a,), (f,), (a, f), (a, f)),\n",
    "):\n",
    "\n",
    "    p_s1__vv = np.full(s.size, np.nan)\n",
    "\n",
    "    for i in range(s.size):\n",
    "\n",
    "        coordinate = [\n",
    "            [np.argmin(abs(np.linspace(v.min(), v.max(), grid_size) - v[i]))]\n",
    "            for v in vs\n",
    "        ]\n",
    "\n",
    "        p_s1__vv[i] = p_s1__v[coordinate]\n",
    "\n",
    "    fpr, tpr, t = roc_curve(s, normalize_nd_array(p_s1__vv, None, \"0-1\"))\n",
    "\n",
    "    math_roc[math][\"fpr\"] = fpr\n",
    "\n",
    "    math_roc[math][\"tpr\"] = tpr\n",
    "\n",
    "    auc_ = auc(fpr, tpr)\n",
    "\n",
    "    math_roc[math][\"auc\"] = auc_\n",
    "\n",
    "    n_permutation_for_roc = 1000\n",
    "\n",
    "    permuting_aucs = np.full(n_permutation_for_roc, np.nan)\n",
    "\n",
    "    permuting_s = s.copy()\n",
    "\n",
    "    for i in range(n_permutation_for_roc):\n",
    "\n",
    "        np.random.shuffle(permuting_s)\n",
    "\n",
    "        permuting_fpr, permuting_tpr, permuting_t = roc_curve(permuting_s, p_s1__vv)\n",
    "\n",
    "        permuting_aucs[i] = auc(permuting_fpr, permuting_tpr)\n",
    "\n",
    "    math_roc[math][\"p-value\"] = compute_empirical_p_value(auc_, permuting_aucs, \"great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:37:20.971630Z",
     "start_time": "2018-05-15T09:37:20.665810Z"
    }
   },
   "outputs": [],
   "source": [
    "from probability.plot_bayesian_nomogram import plot_bayesian_nomogram\n",
    "\n",
    "plot_bayesian_nomogram(\n",
    "    s, 1, 0, grid_size, (p_s__g, p_s__a, p_s__f), (g_name, a_name, f_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:37:20.654097Z",
     "start_time": "2018-05-15T09:37:20.375521Z"
    }
   },
   "outputs": [],
   "source": [
    "from probability.plot.plot.plot_points import plot_points\n",
    "\n",
    "random_roc = np.linspace(0, 1, 16)\n",
    "\n",
    "plot_points(\n",
    "    (random_roc,) + tuple(math_roc[math][\"fpr\"] for math in maths),\n",
    "    (random_roc,) + tuple(math_roc[math][\"tpr\"] for math in maths),\n",
    "    names=(\"Random ROC\",)\n",
    "    + tuple(\n",
    "        \"{} | {:0.3f} | {:0.1e}\".format(\n",
    "            math, math_roc[math][\"auc\"], math_roc[math][\"p-value\"]\n",
    "        )\n",
    "        for math in maths\n",
    "    ),\n",
    "    modes=(\"markers\",) + (\"markers + lines\",) * len(maths),\n",
    "    title=\"ROC: G={}, A={}, F={}\".format(g_name, a_name, f_name),\n",
    "    xaxis_title=\"False Positive Rate\",\n",
    "    yaxis_title=\"True Positive Rate\",\n",
    "    legend_orientation=\"h\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:36:21.162702Z",
     "start_time": "2018-05-15T09:36:21.076230Z"
    }
   },
   "outputs": [],
   "source": [
    "training_sample_x_feature = np.asarray(((0, 1),) * 8 + ((2, 3),) * 8)\n",
    "\n",
    "training_sample_x_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:36:21.235721Z",
     "start_time": "2018-05-15T09:36:21.171772Z"
    }
   },
   "outputs": [],
   "source": [
    "training_sample_class = np.asarray((0,) * 8 + (1,) * 8)\n",
    "\n",
    "training_sample_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:36:21.306027Z",
     "start_time": "2018-05-15T09:36:21.242185Z"
    }
   },
   "outputs": [],
   "source": [
    "testing_sample_x_feature = training_sample_x_feature[::-1]\n",
    "\n",
    "testing_sample_x_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:36:22.865562Z",
     "start_time": "2018-05-15T09:36:21.315750Z"
    }
   },
   "outputs": [],
   "source": [
    "from regression.train_and_regress import train_and_regress\n",
    "\n",
    "testing_sample_class = train_and_regress(\n",
    "    training_sample_x_feature, training_sample_class, testing_sample_x_feature\n",
    ")\n",
    "\n",
    "testing_sample_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T18:25:05.119319Z",
     "start_time": "2018-05-01T18:25:05.092430Z"
    }
   },
   "outputs": [],
   "source": [
    "from sequencing_process.support.support.path import clean_path\n",
    "\n",
    "GRCH_DIRECTORY_PATH = clean_path(\"~/sequencing_process_grch\")\n",
    "\n",
    "assert os.path.isdir(GRCH_DIRECTORY_PATH)\n",
    "\n",
    "PEOPLE_DIRECTORY_PATH = clean_path(\"~/sequencing_process_people\")\n",
    "\n",
    "assert os.path.isdir(PEOPLE_DIRECTORY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T18:25:10.213749Z",
     "start_time": "2018-05-01T18:25:05.122082Z"
    }
   },
   "outputs": [],
   "source": [
    "from sequencing_process.download_clinvar_vcf_gz import download_clinvar_vcf_gz\n",
    "\n",
    "vcf_gz_file_path = download_clinvar_vcf_gz(GRCH_DIRECTORY_PATH, overwrite=True)\n",
    "\n",
    "vcf_gz_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T18:25:11.725257Z",
     "start_time": "2018-05-01T18:25:10.215937Z"
    }
   },
   "outputs": [],
   "source": [
    "from sequencing_process.support.support.compression import gzip_decompress_file\n",
    "\n",
    "vcf_file_path = gzip_decompress_file(vcf_gz_file_path)\n",
    "\n",
    "vcf_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T18:25:19.317124Z",
     "start_time": "2018-05-01T18:25:11.728211Z"
    }
   },
   "outputs": [],
   "source": [
    "from sequencing_process.bgzip_and_tabix import bgzip_and_tabix\n",
    "\n",
    "vcf_gz_file_path = bgzip_and_tabix(vcf_file_path, overwrite=True)\n",
    "\n",
    "vcf_gz_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T18:41:07.762962Z",
     "start_time": "2018-05-01T18:25:19.320712Z"
    }
   },
   "outputs": [],
   "source": [
    "from sequencing_process.make_reference_genome import make_reference_genome\n",
    "\n",
    "fasta_gz_file_path = make_reference_genome(GRCH_DIRECTORY_PATH, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T19:00:45.969194Z",
     "start_time": "2018-05-01T18:41:07.767495Z"
    }
   },
   "outputs": [],
   "source": [
    "from sequencing_process.simulate_sequences_using_dwgsim import (\n",
    "    simulate_sequences_using_dwgsim,\n",
    ")\n",
    "\n",
    "simulate_sequences_using_dwgsim(\n",
    "    fasta_gz_file_path[:-3],\n",
    "    \"{}/simulation\".format(PEOPLE_DIRECTORY_PATH),\n",
    "    n_sequence=int(1e6),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T09:36:04.147455Z",
     "start_time": "2018-05-15T09:35:59.734704Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "from support.multiprocess import multiprocess\n",
    "\n",
    "\n",
    "def function(a, b):\n",
    "\n",
    "    sleep(2)\n",
    "\n",
    "    return a + b\n",
    "\n",
    "\n",
    "returns = multiprocess(function, ((0, 1), (2, 3), (4, 5)), 2)\n",
    "\n",
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from support.df import drop_df_slice_greedily\n",
    "\n",
    "df = pd.DataFrame(np.random.random_sample(size=(2, 4)))\n",
    "\n",
    "df_dropped = drop_df_slice_greedily(df)\n",
    "\n",
    "print(df_dropped)\n",
    "\n",
    "df_dropped = drop_df_slice_greedily(df.T)\n",
    "\n",
    "print(df_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:50:24.456226Z",
     "start_time": "2018-05-07T08:50:23.976033Z"
    }
   },
   "outputs": [],
   "source": [
    "from tables import NoSuchNodeError\n",
    "\n",
    "from variant.support.support.path import clean_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:50:24.489203Z",
     "start_time": "2018-05-07T08:50:24.459430Z"
    }
   },
   "outputs": [],
   "source": [
    "vcf_gz_file_path = clean_path(\"~/people/0/genome.vcf.gz\")\n",
    "\n",
    "assert os.path.isfile(vcf_gz_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:51:09.209519Z",
     "start_time": "2018-05-07T08:50:24.492197Z"
    }
   },
   "outputs": [],
   "source": [
    "from variant.access_vcf_dict import read_vcf_gz_and_make_vcf_dict\n",
    "\n",
    "vcf_dict = read_vcf_gz_and_make_vcf_dict(vcf_gz_file_path)\n",
    "\n",
    "vcf_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:51:09.450030Z",
     "start_time": "2018-05-07T08:51:09.296325Z"
    }
   },
   "outputs": [],
   "source": [
    "vcf_dict[\"meta_information\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:51:09.554895Z",
     "start_time": "2018-05-07T08:51:09.454588Z"
    }
   },
   "outputs": [],
   "source": [
    "vcf_dict[\"vcf_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:51:09.676221Z",
     "start_time": "2018-05-07T08:51:09.558661Z"
    }
   },
   "outputs": [],
   "source": [
    "vcf_dict[\"clean_vcf_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:51:19.465918Z",
     "start_time": "2018-05-07T08:51:09.679655Z"
    }
   },
   "outputs": [],
   "source": [
    "from variant.access_vcf import count_vcf_gz_rows\n",
    "\n",
    "field_n = count_vcf_gz_rows(\n",
    "    vcf_gz_file_path,\n",
    "    info_fields_to_count=(\n",
    "        \"ANN\",\n",
    "        \"CAF\",\n",
    "        \"CLNDISDB\",\n",
    "        \"CLNDN\",\n",
    "        \"CLNSIG\",\n",
    "        \"CLNREVSTAT\",\n",
    "        \"CLNVI\",\n",
    "    ),\n",
    "    format_fields_to_count=(\"GT\", \"AD\", \"DP\"),\n",
    ")\n",
    "\n",
    "field_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:53:18.290946Z",
     "start_time": "2018-05-07T08:51:19.470204Z"
    }
   },
   "outputs": [],
   "source": [
    "from variant.VariantHDF5 import VariantHDF5\n",
    "\n",
    "variant_hdf5 = VariantHDF5(vcf_gz_file_path, reset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:53:18.833435Z",
     "start_time": "2018-05-07T08:53:18.302280Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    variant_dict = variant_hdf5.get_variant_by_id(\"rs235\")\n",
    "\n",
    "    print(variant_dict)\n",
    "\n",
    "except KeyError as exception:\n",
    "\n",
    "    warn(\"(get_variant_by_id) KeyError: {}.\".format(exception))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:53:18.905984Z",
     "start_time": "2018-05-07T08:53:18.844573Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    variant_dict = variant_hdf5.get_variant_by_id(\"rs88888888\")\n",
    "\n",
    "    print(variant_dict)\n",
    "\n",
    "except KeyError as exception:\n",
    "\n",
    "    warn(\"(get_variant_by_id) KeyError: {}.\".format(exception))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:53:18.970284Z",
     "start_time": "2018-05-07T08:53:18.911880Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    variant_dict = variant_hdf5.get_variants_by_gene(\"KRAS\")\n",
    "\n",
    "    print(variant_dict)\n",
    "\n",
    "except KeyError as exception:\n",
    "\n",
    "    warn(\"(get_variants_by_gene) KeyError: {}.\".format(exception))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:53:19.051008Z",
     "start_time": "2018-05-07T08:53:18.980550Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    variant_dict = variant_hdf5.get_variants_by_gene(\"Kwat\")\n",
    "\n",
    "    print(variant_dict)\n",
    "\n",
    "except KeyError as exception:\n",
    "\n",
    "    warn(\"(get_variants_by_gene) KeyError: {}.\".format(exception))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:53:19.158006Z",
     "start_time": "2018-05-07T08:53:19.057600Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    variant_dict = variant_hdf5.get_variants_by_region(\"8\", 0, 80000)\n",
    "\n",
    "    print(variant_dict)\n",
    "\n",
    "except NoSuchNodeError as exception:\n",
    "\n",
    "    warn(\"(get_features_by_region) NoSuchNodeError: {}.\".format(exception))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:53:19.254818Z",
     "start_time": "2018-05-07T08:53:19.176433Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    variant_dict = variant_hdf5.get_variants_by_region(\"88888888\", 0, 80000)\n",
    "\n",
    "    print(variant_dict)\n",
    "\n",
    "except NoSuchNodeError as exception:\n",
    "\n",
    "    warn(\"(get_features_by_region) NoSuchNodeError: {}.\".format(exception))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T08:53:19.385464Z",
     "start_time": "2018-05-07T08:53:19.261785Z"
    }
   },
   "outputs": [],
   "source": [
    "from variant.access_maf import make_maf_from_vcf\n",
    "\n",
    "make_maf_from_vcf(vcf_gz_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
