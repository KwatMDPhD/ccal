{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_importable_name_from_py_file_path(py_file_path):\n",
    "\n",
    "    py_file_name == py_file_path.split(\"/\")[-1]\n",
    "\n",
    "    py_file_name_without_py = py_file_name[: -len(\".py\")]\n",
    "    \n",
    "    if not (py_file_name_without_py.islower() or py_file_name_without_py.isupper()):\n",
    "        \n",
    "        print(f\"{py_file_name_without_py} has mixed character cases.\")\n",
    "        \n",
    "    if py_file_name_without_py.isupper():\n",
    "\n",
    "        importable_names = [py_file_name_without_py]\n",
    "        \n",
    "    else:\n",
    "\n",
    "        importable_names = []\n",
    "\n",
    "        with open(py_file_path) as io:\n",
    "\n",
    "            for line in io.readlines():\n",
    "\n",
    "                for prefix in (\"def \", \"class \"):\n",
    "\n",
    "                    if line.startswith(prefix):\n",
    "\n",
    "                        if \"(\" in line:\n",
    "\n",
    "                            separator = \"(\"\n",
    "\n",
    "                        elif \":\" in line:\n",
    "\n",
    "                            separator = \":\"\n",
    "\n",
    "                        importable_names.append(\n",
    "                            line.strip().split(separator)[0][len(prefix) :]\n",
    "                        )\n",
    "                        \n",
    "    _names = [name for name in importable_names if name.startswith(\"_\")]\n",
    "\n",
    "    if 0 < len(_names):\n",
    "\n",
    "        print(\"\\t\" + \"\\n\\t\".join(_names))\n",
    "\n",
    "    importable_names = set(importable_names) - set(_names)\n",
    "\n",
    "    if len(importable_names) != 1:\n",
    "        \n",
    "        n_importable_names = len(importable_names)\n",
    "\n",
    "        raise ValueError(f\"N importable names ({n_importable_names}) != 1\")\n",
    "\n",
    "    importable_name = importable_names.pop()\n",
    "\n",
    "    if importable_name != py_file_name_without_py:\n",
    "\n",
    "        raise ValueError(\n",
    "            f\"{py_file_name_without_py}(.py) != {importable_name}\"\n",
    "        )\n",
    "\n",
    "    return importable_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALMOST_ZERO.py\n",
      "\n",
      "BAD_VALUES.py\n",
      "\n",
      "DATA_DIRECTORY_PATH.py\n",
      "\n",
      "FRACTION_GRID_EXTENSION.py\n",
      "\n",
      "GPSMap.py\n",
      "GPSMap has mixed character cases.\n",
      "\t_check_node_x_element\n",
      "\t_make_element_x_dimension\n",
      "\t_plot\n",
      "\n",
      "NONE_STRS.py\n",
      "\n",
      "N_GRID.py\n",
      "\n",
      "RANDOM_SEED.py\n",
      "\n",
      "VCF_ANN_KEYS.py\n",
      "\n",
      "VCF_COLUMNS.py\n",
      "\n",
      "__init__.py\n",
      "\n",
      "__pycache__\n",
      "\n",
      "add_conda_to_path.py\n",
      "\n",
      "apply_function_on_2_vectors.py\n",
      "\n",
      "apply_function_on_slices_from_2_dataframes.py\n",
      "\n",
      "apply_function_on_slices_from_2_matrices.py\n",
      "\n",
      "call_function_with_multiprocess.py\n",
      "\n",
      "cast_object_to_builtin.py\n",
      "\n",
      "check_array_for_bad.py\n",
      "\n",
      "clean_and_write_dataframe_to_tsv.py\n",
      "\n",
      "clip_array_by_standard_deviation.py\n",
      "\n",
      "cluster_clustering_x_element_and_compute_ccc.py\n",
      "\n",
      "cluster_matrix.py\n",
      "\t_compute_euclidean_distance\n",
      "\n",
      "compute_empirical_p_value.py\n",
      "\n",
      "compute_empirical_p_values_and_fdrs.py\n",
      "\n",
      "compute_information_coefficient_between_2_vectors.py\n",
      "\n",
      "compute_information_distance_between_2_vectors.py\n",
      "\n",
      "compute_joint_probability.py\n",
      "\n",
      "compute_kullback_leibler_divergence_between_2_pdfs.py\n",
      "\n",
      "compute_matrix_norm.py\n",
      "\n",
      "compute_normal_pdf_margin_of_error.py\n",
      "\n",
      "compute_posterior_probability.py\n",
      "\n",
      "compute_vector_bandwidth.py\n",
      "\n",
      "compute_vector_context.py\n",
      "\t_compute_pdf_context\n",
      "\n",
      "compute_vector_entropy.py\n",
      "\n",
      "correlate_2_vectors.py\n",
      "\n",
      "count_gene_impacts_from_variant_dicts.py\n",
      "\n",
      "data\n",
      "\n",
      "download_and_parse_geo.py\n",
      "\n",
      "download_url.py\n",
      "\n",
      "download_url_and_extract.py\n",
      "\n",
      "drop_dataframe_slice.py\n",
      "\n",
      "drop_dataframe_slice_greedily.py\n",
      "\n",
      "echo_or_print_str.py\n",
      "\n",
      "establish_path.py\n",
      "\n",
      "estimate_kernel_density.py\n",
      "\n",
      "exit_.py\n",
      "\n",
      "fit_each_dataframe_row_to_skew_t_pdf.py\n",
      "\t_fit_each_dataframe_row_to_skew_t_pdf\n",
      "\n",
      "fit_vector_to_skew_t_pdf.py\n",
      "\n",
      "flatten_nested_iterable.py\n",
      "\n",
      "get_child_paths.py\n",
      "\n",
      "get_chromosome_size_from_fasta_gz.py\n",
      "\n",
      "get_colormap_colors.py\n",
      "\n",
      "get_conda_environments.py\n",
      "\n",
      "get_conda_prefix.py\n",
      "\n",
      "get_d_dimensions.py\n",
      "\n",
      "get_data_type.py\n",
      "\n",
      "get_gff3_attribute.py\n",
      "\n",
      "get_git_versions.py\n",
      "\n",
      "get_intersections_between_2_vectors.py\n",
      "\n",
      "get_machine.py\n",
      "\n",
      "get_sequence_from_fasta_or_fasta_gz.py\n",
      "\n",
      "get_shell_environment.py\n",
      "\n",
      "get_triangulation_edges_from_point_x_dimension.py\n",
      "\n",
      "get_variant_start_and_end_positions.py\n",
      "\n",
      "get_variants_from_vcf_or_vcf_gz.py\n",
      "\n",
      "get_vcf_genotype.py\n",
      "\n",
      "get_vcf_info.py\n",
      "\n",
      "get_vcf_info_ann.py\n",
      "\n",
      "get_vcf_sample_format.py\n",
      "\n",
      "group_and_apply_function_on_each_group_in_iterable.py\n",
      "\n",
      "hierarchical_consensus_cluster_dataframe.py\n",
      "\n",
      "hierarchical_consensus_cluster_dataframe_with_ks.py\n",
      "\n",
      "infer.py\n",
      "\n",
      "infer_assuming_independence.py\n",
      "\n",
      "initialize_logger.py\n",
      "\n",
      "install_and_activate_conda.py\n",
      "\n",
      "install_python_libraries.py\n",
      "\n",
      "is_conda_directory_path.py\n",
      "\n",
      "is_in_git_repository.py\n",
      "\n",
      "is_program.py\n",
      "\n",
      "is_sorted_array.py\n",
      "\n",
      "is_str_version.py\n",
      "\n",
      "log_and_return_response.py\n",
      "\n",
      "log_array.py\n",
      "\n",
      "make_binary_dataframe_from_categorical_series.py\n",
      "\n",
      "make_colorscale_from_colors.py\n",
      "\n",
      "make_context_matrix.py\n",
      "\t_make_context_matrix\n",
      "\n",
      "make_gitkeep.py\n",
      "\n",
      "make_match_panel.py\n",
      "\t_match_target_and_data\n",
      "\t_permute_target_and_match_target_and_data\n",
      "\t_match_target_and_data_and_compute_statistics\n",
      "\n",
      "make_match_panel_annotations.py\n",
      "\n",
      "make_match_panel_summary.py\n",
      "\n",
      "make_match_panels.py\n",
      "\n",
      "make_mesh_grid_point_x_dimension.py\n",
      "\n",
      "make_reflecting_grid.py\n",
      "\n",
      "make_variant_dict_consistent.py\n",
      "\n",
      "make_variant_dict_from_vcf_row.py\n",
      "\n",
      "make_variant_n_from_vcf_file_path.py\n",
      "\n",
      "make_variant_n_from_vcf_row.py\n",
      "\n",
      "make_vector_grid.py\n",
      "\n",
      "map_objects_to_ints.py\n",
      "\n",
      "merge_2_dicts_with_function.py\n",
      "\n",
      "mf_by_multiple_v_and_h.py\n",
      "\n",
      "mf_by_multiplicative_update.py\n",
      "\n",
      "mf_consensus_cluster_dataframe.py\n",
      "\n",
      "mf_consensus_cluster_dataframe_with_ks.py\n",
      "\n",
      "nmf_by_sklearn.py\n",
      "\n",
      "normalize_array.py\n",
      "\t_normalize_array\n",
      "\n",
      "normalize_cell_line_names.py\n",
      "\n",
      "normalize_contig.py\n",
      "\n",
      "normalize_file_name.py\n",
      "\n",
      "normalize_git_url.py\n",
      "\n",
      "normalize_path.py\n",
      "\n",
      "normalize_series_or_dataframe.py\n",
      "\n",
      "pick_colors.py\n",
      "\n",
      "plot_bayesian_nomogram.py\n",
      "\n",
      "plot_bubble_map.py\n",
      "\n",
      "plot_context.py\n",
      "\n",
      "plot_heat_map.py\n",
      "\n",
      "plot_histogram.py\n",
      "\n",
      "plot_mesh_grid.py\n",
      "\n",
      "plot_plotly_figure.py\n",
      "\n",
      "plot_scatter_and_annotate.py\n",
      "\n",
      "print_function_information.py\n",
      "\t_function\n",
      "\n",
      "print_header_in_terminal.py\n",
      "\n",
      "process_feature_x_sample.py\n",
      "\n",
      "read_gff3.py\n",
      "\n",
      "read_gmt.py\n",
      "\n",
      "read_gps_map.py\n",
      "\n",
      "read_json.py\n",
      "\n",
      "read_matrix_market.py\n",
      "\n",
      "read_where_and_map_column_name_on_hdf5_table.py\n",
      "\n",
      "remove_path.py\n",
      "\n",
      "rescale_x_y_coordiantes_in_polar_coordiante.py\n",
      "\n",
      "run_command.py\n",
      "\n",
      "sample_from_each_series_value.py\n",
      "\n",
      "scale_point_x_dimension_dimension.py\n",
      "\n",
      "select_and_group_feature_x_tcga_sample_by_sample_type.py\n",
      "\n",
      "select_gene_symbol.py\n",
      "\n",
      "select_series_indices.py\n",
      "\n",
      "separate_information_x_sample.py\n",
      "\n",
      "shuffle_each_matrix_slice.py\n",
      "\n",
      "skip_quote_and_split_str.py\n",
      "\n",
      "solve_ax_equal_b.py\n",
      "\n",
      "solve_for_h.py\n",
      "\n",
      "split_codons.py\n",
      "\n",
      "split_dataframe.py\n",
      "\n",
      "summarize_feature_x_sample.py\n",
      "\n",
      "title_str.py\n",
      "\n",
      "train_and_classify.py\n",
      "\n",
      "train_and_regress.py\n",
      "\n",
      "unmesh.py\n",
      "\n",
      "untitle_str.py\n",
      "\n",
      "update_h_by_multiplicative_update.py\n",
      "\n",
      "update_variant_dict.py\n",
      "\n",
      "update_w_by_multiplicative_update.py\n",
      "\n",
      "write_gps_map.py\n",
      "\n",
      "write_json.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import_lines = []\n",
    "\n",
    "for py_file_name in sorted(os.listdir(path=os.path.join(\"..\", \"kraft\"))):\n",
    "\n",
    "    print(py_file_name)\n",
    "\n",
    "    if py_file_name != \"__init__.py\" and py_file_name.endswith(\".py\"):\n",
    "        \n",
    "        importable_name = get_importable_name_from_py_file_path(\n",
    "                    os.path.join(\"..\", \"kraft\", py_file_name)\n",
    "                )\n",
    "\n",
    "        import_lines.append(\n",
    "            f\"from .{importable_name} import {importable_name}\"\n",
    "        )\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"..\", \"kraft\", \"__init__.py\"), mode=\"w\") as io:\n",
    "\n",
    "    io.write('from plotly.io import templates\\ntemplates.default = \"plotly_white\"\\n')\n",
    "\n",
    "    io.writelines(\"\\n\".join(import_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dir(kraft)))\n",
    "\n",
    "dir(kraft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file_path in enumerate(sorted(os.listdir())):\n",
    "\n",
    "    if file_path.endswith(\".ipynb\") and not file_path.startswith(\"_\"):\n",
    "\n",
    "        print(i, file_path)\n",
    "\n",
    "        subprocess.run(\n",
    "            \"jupyter nbconvert --execute --ExecutePreprocessor.timeout=-1 --inplace {}\".format(\n",
    "                file_path\n",
    "            ),\n",
    "            shell=True,\n",
    "            check=True,\n",
    "        )\n",
    "\n",
    "        subprocess.run(\"clean_ipynb {}\".format(file_path), shell=True, check=True)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
